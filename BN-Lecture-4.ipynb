{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdf811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be based on MLP but more towards how we optimize training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd76dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c53fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aff3725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91451263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fcab97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f7f9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "# MLP revisited\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5) #* 0.2\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.01\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.01 # fix initialization, why not zero ? \n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0 # fix initialization to minimize logits value\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.ones((1, n_hidden))\n",
    "bnbias = torch.zeros((1, n_hidden))\n",
    "bnmean_running = torch.zeros((1, n_hidden))\n",
    "bnstd_running = torch.ones((1, n_hidden))\n",
    "\n",
    "parameters = [C, W1,b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b842f404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3147\n",
      "  10000/ 200000: 2.1984\n",
      "  20000/ 200000: 2.3375\n",
      "  30000/ 200000: 2.4359\n",
      "  40000/ 200000: 2.0119\n",
      "  50000/ 200000: 2.2595\n",
      "  60000/ 200000: 2.4775\n",
      "  70000/ 200000: 2.1020\n",
      "  80000/ 200000: 2.2788\n",
      "  90000/ 200000: 2.1862\n",
      " 100000/ 200000: 1.9474\n",
      " 110000/ 200000: 2.3010\n",
      " 120000/ 200000: 1.9837\n",
      " 130000/ 200000: 2.4523\n",
      " 140000/ 200000: 2.3839\n",
      " 150000/ 200000: 2.1987\n",
      " 160000/ 200000: 1.9733\n",
      " 170000/ 200000: 1.8668\n",
      " 180000/ 200000: 1.9973\n",
      " 190000/ 200000: 1.8347\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[Xb] # embed the characters into vectors, this is gaussian \n",
    "  embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "  # Linear layer\n",
    "  hpreact = embcat @ W1 + b1 # hidden layer pre-activation, want close to zero , NOTICE b1 doesnt change since we later substract it from mean so. wecan remove it\n",
    "  #hpreact = bngain*(hpreact - hpreact.mean(0, keepdim=True)) / hpreact.std(0, keepdim=True) +bnbias \n",
    "  # BatchNorm layer\n",
    "  # -------------------------------------------------------------\n",
    "  bnmeani = hpreact.mean(0, keepdim=True)\n",
    "  bnstdi = hpreact.std(0, keepdim=True)\n",
    "  hpreact = bngain * (hpreact - bnmeani) / bnstdi + bnbias\n",
    "  with torch.no_grad(): \n",
    "    bnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani # recv small update from current ith iteration\n",
    "    bnstd_running = 0.999 * bnstd_running + 0.001 * bnstdi\n",
    "  # -------------------------------------------------------------\n",
    "  # Non-linearity\n",
    "  h = torch.tanh(hpreact) # hidden layer\n",
    "  logits = h @ W2 + b2 # output layer\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  # update\n",
    "  lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "#   print(logits)\n",
    "#   break  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee70875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibrate the batch norm at the end of training \n",
    "with torch.no_grad():\n",
    "    # pass the training set through\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    # measure the mean and std over entire training set\n",
    "    bnmean = hpreact.mean(0, keepdim=True) \n",
    "    bnstd = hpreact.std(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae0e8edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3355,  0.6776, -0.9133,  1.0163,  1.0865,  1.0938,  1.7437, -2.1208,\n",
       "          0.5730,  1.4455, -1.6343, -2.7372, -0.4752, -0.1412, -0.0745, -1.1722,\n",
       "          0.6851, -2.6219, -0.1065,  1.6325, -0.7706, -0.3062,  0.0479,  0.6116,\n",
       "          1.1173,  0.2427,  2.0500,  0.5832,  0.8527,  1.7680, -0.3625, -0.8355,\n",
       "         -0.0854, -0.5177, -0.3806, -1.0699, -0.0786,  0.3487, -0.5808,  0.9875,\n",
       "         -0.4427, -1.3082, -0.2871, -0.2332,  0.6850,  0.6850,  2.0857, -0.7608,\n",
       "          2.3866,  1.8734,  0.8259,  0.2803,  1.8897,  0.4709,  0.6739, -1.8940,\n",
       "         -0.0401,  0.4338,  1.3760, -0.8910, -0.4523,  1.1754,  0.5613,  0.6051,\n",
       "          1.5858,  1.2261, -1.0111,  2.1495, -0.6393,  0.0938, -0.2864, -0.4856,\n",
       "          0.9632, -1.0461, -2.9990,  0.6391,  1.4327, -0.1590,  0.0940,  0.5253,\n",
       "          0.2508,  1.2521,  2.0388,  0.6608,  0.0691, -0.0813, -1.6723,  0.2933,\n",
       "          2.2423, -0.0210, -0.6666,  1.4253, -0.8411, -1.2248, -1.0128,  0.2230,\n",
       "          0.2113, -0.3226,  0.1141, -0.6350,  0.1848,  0.1165, -1.3947,  0.2343,\n",
       "          0.2170, -0.3493, -0.3409, -0.1918,  0.9244, -0.8073,  0.7147,  0.2383,\n",
       "          0.3964,  1.2354,  2.8623,  2.0470,  0.8419,  0.8480,  0.3483, -0.3153,\n",
       "         -1.0648, -1.4465,  0.3517,  1.1174, -1.1265,  0.0688, -0.2204, -0.4964,\n",
       "         -0.8558, -1.0849,  2.8098, -1.2867,  0.6543,  1.8674,  0.9511,  1.0606,\n",
       "         -0.7020,  1.8505,  0.1528,  0.4583,  1.6234, -0.1899,  1.9335,  0.2938,\n",
       "          0.4391,  0.2065,  1.1369, -0.6884,  0.1559,  0.5906, -1.5956, -0.2324,\n",
       "          1.7724,  1.2664,  0.9917, -0.4957,  1.4023, -1.6664,  0.0178,  0.4224,\n",
       "          0.5857, -0.4225,  0.9377, -1.1793, -0.4486, -0.7184, -0.3307, -0.4207,\n",
       "         -2.1519, -0.1098,  1.1733, -2.1530,  0.1215, -0.8929, -0.9959,  0.9028,\n",
       "          1.3427, -0.7526,  1.3065, -1.5016,  1.8439,  0.9704,  0.8244, -0.7247,\n",
       "          0.3621,  0.0768, -0.9657,  0.1345,  1.8784,  0.9191, -0.5020,  1.6438,\n",
       "         -0.7394,  0.2081,  0.1425,  1.2711,  1.8083, -0.8162,  0.2586,  1.2403]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "962eabc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3539,  0.6872, -0.9001,  1.0159,  1.0894,  1.0862,  1.7389, -2.1357,\n",
       "          0.5608,  1.4246, -1.6445, -2.7426, -0.4861, -0.1510, -0.0687, -1.1550,\n",
       "          0.6891, -2.6399, -0.1283,  1.6240, -0.7732, -0.2864,  0.0467,  0.6119,\n",
       "          1.1172,  0.2433,  2.0542,  0.5778,  0.8515,  1.7729, -0.3741, -0.8385,\n",
       "         -0.0831, -0.5198, -0.3817, -1.0699, -0.0780,  0.3370, -0.5768,  0.9935,\n",
       "         -0.4507, -1.3313, -0.2895, -0.2298,  0.6877,  0.6936,  2.0835, -0.7759,\n",
       "          2.3804,  1.8613,  0.8117,  0.2735,  1.8802,  0.4704,  0.6656, -1.8962,\n",
       "         -0.0420,  0.4356,  1.3924, -0.8906, -0.4676,  1.1688,  0.5539,  0.6001,\n",
       "          1.5853,  1.2103, -1.0171,  2.1421, -0.6330,  0.1070, -0.2926, -0.4831,\n",
       "          0.9506, -1.0144, -2.9925,  0.6268,  1.4404, -0.1574,  0.0955,  0.5159,\n",
       "          0.2487,  1.2401,  2.0104,  0.6695,  0.0768, -0.0851, -1.6767,  0.2963,\n",
       "          2.2374, -0.0100, -0.6669,  1.4356, -0.8431, -1.2317, -1.0220,  0.2201,\n",
       "          0.1929, -0.3261,  0.1108, -0.6206,  0.1795,  0.1089, -1.4007,  0.2215,\n",
       "          0.2301, -0.3369, -0.3340, -0.1849,  0.9342, -0.8288,  0.7119,  0.2475,\n",
       "          0.3813,  1.2447,  2.8427,  2.0338,  0.8295,  0.8458,  0.3483, -0.3078,\n",
       "         -1.0773, -1.4394,  0.3424,  1.1274, -1.1252,  0.0692, -0.2308, -0.4936,\n",
       "         -0.8471, -1.0785,  2.8080, -1.2824,  0.6541,  1.8701,  0.9662,  1.0696,\n",
       "         -0.7051,  1.8326,  0.1624,  0.4782,  1.6376, -0.1962,  1.9364,  0.2986,\n",
       "          0.4300,  0.2062,  1.1390, -0.6907,  0.1571,  0.5883, -1.5947, -0.2229,\n",
       "          1.7796,  1.2689,  0.9813, -0.4950,  1.4052, -1.6645,  0.0248,  0.4152,\n",
       "          0.5742, -0.4044,  0.9335, -1.1684, -0.4574, -0.7229, -0.3192, -0.4214,\n",
       "         -2.1397, -0.1036,  1.1620, -2.1602,  0.1196, -0.8847, -0.9970,  0.9115,\n",
       "          1.3360, -0.7412,  1.2991, -1.5061,  1.8279,  0.9732,  0.8192, -0.7259,\n",
       "          0.3556,  0.0714, -0.9718,  0.1299,  1.8912,  0.9107, -0.4950,  1.6493,\n",
       "         -0.7601,  0.2008,  0.1606,  1.2586,  1.8110, -0.8021,  0.2453,  1.2369]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnmean_running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14888b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11e388ca0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# black 0 and white 1 for h, white places all neuron will be destroyed\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(h.abs() > 0.99, cmap='gray', interpolation='nearest')\n",
    "# if column is white then nothing is passing by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad0fab04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAj6ElEQVR4nO3df3BU1f3/8Vd+kA0BNiFgEikBQSgQCaJQwqIVKykBY4sFp6AORstgpQGFWIS0CAXsEIEBf0wUh+GHnUqpOKKCgCIKVl0BIyjya8SCYHEDSEn4IQlJzvePfnK/rgmQTTbZk/B8zOwMe+65d887Z3+8uHvv3TBjjBEAAIBFwkM9AAAAgB8joAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArBMZ6gHURkVFhY4ePapWrVopLCws1MMBAAA1YIzR6dOn1a5dO4WHX3ofSaMMKEePHlVycnKohwEAAGrhyJEjat++/SX7NMqA0qpVK0n/K9Dtdod4NAAAoCaKi4uVnJzsfI5fSqMMKJVf67jdbgIKAACNTE0Oz+AgWQAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrRIZ6ADa6Zuqbl+1zKC+zAUYCAMCViT0oAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA60SGegAAAKBhXTP1zcv2OZSX2QAjuTj2oAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6dQooeXl5CgsL08SJE5228+fPKzs7W23atFHLli01YsQIFRYW+q13+PBhZWZmKiYmRgkJCZo8ebLKysrqMhQAANCE1DqgbN++XS+88IJ69erl1z5p0iStWbNGq1at0pYtW3T06FENHz7cWV5eXq7MzEyVlpbqo48+0osvvqjly5dr+vTpta8CAAA0KbUKKGfOnNG9996rxYsXq3Xr1k57UVGRlixZogULFui2225Tnz59tGzZMn300Uf6+OOPJUlvv/229uzZo7///e/q3bu3hg4dqtmzZys/P1+lpaXBqQoAADRqtQoo2dnZyszMVHp6ul97QUGBLly44NfevXt3dejQQV6vV5Lk9XqVmpqqxMREp09GRoaKi4u1e/fuah+vpKRExcXFfjcAANB0RQa6wsqVK/Xpp59q+/btVZb5fD5FRUUpLi7Orz0xMVE+n8/p88NwUrm8cll15syZo5kzZwY6VAAA0EgFtAflyJEjeuSRR/TSSy8pOjq6vsZURW5uroqKipzbkSNHGuyxAQBAwwsooBQUFOjYsWO68cYbFRkZqcjISG3ZskXPPPOMIiMjlZiYqNLSUp06dcpvvcLCQiUlJUmSkpKSqpzVU3m/ss+PuVwuud1uvxsAAGi6AgoogwYN0q5du7Rz507n1rdvX917773Ov5s1a6ZNmzY56+zfv1+HDx+Wx+ORJHk8Hu3atUvHjh1z+mzcuFFut1spKSlBKgsAADRmAR2D0qpVK/Xs2dOvrUWLFmrTpo3TPmbMGOXk5Cg+Pl5ut1sTJkyQx+NR//79JUmDBw9WSkqKRo8erblz58rn82natGnKzs6Wy+UKUlkAAKAxC/gg2ctZuHChwsPDNWLECJWUlCgjI0PPPfecszwiIkJr167VuHHj5PF41KJFC2VlZWnWrFnBHgoAAGik6hxQNm/e7Hc/Ojpa+fn5ys/Pv+g6HTt21Lp16+r60AAAoInit3gAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQIKKM8//7x69eolt9stt9stj8ej9evXO8vPnz+v7OxstWnTRi1bttSIESNUWFjot43Dhw8rMzNTMTExSkhI0OTJk1VWVhacagAAQJMQUEBp37698vLyVFBQoE8++US33Xabhg0bpt27d0uSJk2apDVr1mjVqlXasmWLjh49quHDhzvrl5eXKzMzU6Wlpfroo4/04osvavny5Zo+fXpwqwIAAI1amDHG1GUD8fHxmjdvnu666y5dddVVWrFihe666y5J0r59+9SjRw95vV71799f69ev1x133KGjR48qMTFRkrRo0SJNmTJFx48fV1RUVI0es7i4WLGxsSoqKpLb7a7L8Kt1zdQ3L9vnUF5m0B8XAICGEKrPuUA+v2t9DEp5eblWrlyps2fPyuPxqKCgQBcuXFB6errTp3v37urQoYO8Xq8kyev1KjU11QknkpSRkaHi4mJnL0x1SkpKVFxc7HcDAABNV8ABZdeuXWrZsqVcLpceeughrV69WikpKfL5fIqKilJcXJxf/8TERPl8PkmSz+fzCyeVyyuXXcycOXMUGxvr3JKTkwMdNgAAaEQCDijdunXTzp07tXXrVo0bN05ZWVnas2dPfYzNkZubq6KiIud25MiRen08AAAQWpGBrhAVFaUuXbpIkvr06aPt27fr6aef1siRI1VaWqpTp0757UUpLCxUUlKSJCkpKUnbtm3z217lWT6VfarjcrnkcrkCHSoAAGik6nwdlIqKCpWUlKhPnz5q1qyZNm3a5Czbv3+/Dh8+LI/HI0nyeDzatWuXjh075vTZuHGj3G63UlJS6joUAADQRAS0ByU3N1dDhw5Vhw4ddPr0aa1YsUKbN2/WW2+9pdjYWI0ZM0Y5OTmKj4+X2+3WhAkT5PF41L9/f0nS4MGDlZKSotGjR2vu3Lny+XyaNm2asrOz2UMCAAAcAQWUY8eO6b777tO3336r2NhY9erVS2+99ZZ++ctfSpIWLlyo8PBwjRgxQiUlJcrIyNBzzz3nrB8REaG1a9dq3Lhx8ng8atGihbKysjRr1qzgVgUAABq1Ol8HJRS4DgoAALXXpK+DAgAAUF8IKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYJzLUAwAAAMFzzdQ3Qz2EoCCg1FJNngCH8jIbYCQAADQ9fMUDAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWCSigzJkzRz/72c/UqlUrJSQk6M4779T+/fv9+pw/f17Z2dlq06aNWrZsqREjRqiwsNCvz+HDh5WZmamYmBglJCRo8uTJKisrq3s1AACgSQgooGzZskXZ2dn6+OOPtXHjRl24cEGDBw/W2bNnnT6TJk3SmjVrtGrVKm3ZskVHjx7V8OHDneXl5eXKzMxUaWmpPvroI7344otavny5pk+fHryqAABAoxZmjDG1Xfn48eNKSEjQli1bdMstt6ioqEhXXXWVVqxYobvuukuStG/fPvXo0UNer1f9+/fX+vXrdccdd+jo0aNKTEyUJC1atEhTpkzR8ePHFRUVddnHLS4uVmxsrIqKiuR2u2s7/Iu6ZuqbQdnOobzMoGwHAICasvkzLJDP7zodg1JUVCRJio+PlyQVFBTowoULSk9Pd/p0795dHTp0kNfrlSR5vV6lpqY64USSMjIyVFxcrN27d1f7OCUlJSouLva7AQCApqvWAaWiokITJ07UTTfdpJ49e0qSfD6foqKiFBcX59c3MTFRPp/P6fPDcFK5vHJZdebMmaPY2FjnlpycXNthAwCARqDWASU7O1tffPGFVq5cGczxVCs3N1dFRUXO7ciRI/X+mAAAIHQia7PS+PHjtXbtWr3//vtq3769056UlKTS0lKdOnXKby9KYWGhkpKSnD7btm3z217lWT6VfX7M5XLJ5XLVZqgAAKARCmgPijFG48eP1+rVq/Xuu++qU6dOfsv79OmjZs2aadOmTU7b/v37dfjwYXk8HkmSx+PRrl27dOzYMafPxo0b5Xa7lZKSUpdaAABAExHQHpTs7GytWLFCr7/+ulq1auUcMxIbG6vmzZsrNjZWY8aMUU5OjuLj4+V2uzVhwgR5PB71799fkjR48GClpKRo9OjRmjt3rnw+n6ZNm6bs7Gz2kgAAAEkBBpTnn39eknTrrbf6tS9btkz333+/JGnhwoUKDw/XiBEjVFJSooyMDD333HNO34iICK1du1bjxo2Tx+NRixYtlJWVpVmzZtWtEgAA0GQEFFBqcsmU6Oho5efnKz8//6J9OnbsqHXr1gXy0AAA4ArCb/EAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALBOra4ki5qpyS9K8ovHAABUxR4UAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdriQLAEAjUJOrkzcl7EEBAADWIaAAAADrEFAAAIB1OAYFAIAQu9KOL6kJAkqI1eRJeSgvswFGAgCAPfiKBwAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1+DXjRoBfPAYAXGnYgwIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIcLtQEAUI9qcrFNVMUeFAAAYB32oAAIGn6WAUCwsAcFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1OIsHfjgLAwBgA/agAAAA6xBQAACAdfiKBwBwUXzti1BhDwoAALAOe1CAJo7/AcMGPA8RKPagAAAA6xBQAACAdfiKBwgAu6mBK0dNXu+oPwQUwFJXchi6kmsH8D8ElCaCN3Q0FvyvFEBNEFAAAFZoyP9oEZTtR0AB/g9vWABgDwIKQoavpVDfeI4BjVfAAeX999/XvHnzVFBQoG+//VarV6/WnXfe6Sw3xmjGjBlavHixTp06pZtuuknPP/+8unbt6vQ5efKkJkyYoDVr1ig8PFwjRozQ008/rZYtWwalKFxZ+BC6MrHHC2jaAr4OytmzZ3X99dcrPz+/2uVz587VM888o0WLFmnr1q1q0aKFMjIydP78eafPvffeq927d2vjxo1au3at3n//fT344IO1rwIAADQpAe9BGTp0qIYOHVrtMmOMnnrqKU2bNk3Dhg2TJP3tb39TYmKiXnvtNY0aNUp79+7Vhg0btH37dvXt21eS9Oyzz+r222/X/Pnz1a5duzqUAwChwZ68hsGesytHUI9BOXjwoHw+n9LT05222NhYpaWlyev1atSoUfJ6vYqLi3PCiSSlp6crPDxcW7du1W9+85sq2y0pKVFJSYlzv7i4OJjDRj3gTQQAUBdBvdS9z+eTJCUmJvq1JyYmOst8Pp8SEhL8lkdGRio+Pt7p82Nz5sxRbGysc0tOTg7msAEAgGUaxW/x5ObmqqioyLkdOXIk1EMCAAD1KKgBJSkpSZJUWFjo115YWOgsS0pK0rFjx/yWl5WV6eTJk06fH3O5XHK73X43AADQdAX1GJROnTopKSlJmzZtUu/evSX973iRrVu3aty4cZIkj8ejU6dOqaCgQH369JEkvfvuu6qoqFBaWlowh4MfuZKPC7GtdtvGAwC2CTignDlzRgcOHHDuHzx4UDt37lR8fLw6dOigiRMn6oknnlDXrl3VqVMnPf7442rXrp1zrZQePXpoyJAhGjt2rBYtWqQLFy5o/PjxGjVqFGfwAAAASbUIKJ988ol+8YtfOPdzcnIkSVlZWVq+fLkee+wxnT17Vg8++KBOnTqlm2++WRs2bFB0dLSzzksvvaTx48dr0KBBzoXannnmmSCUAwAAmoKAA8qtt94qY8xFl4eFhWnWrFmaNWvWRfvEx8drxYoVgT40LMHXE/ZgLhpGQ/6d+cE84H/4LR4AaGS4KByuBI3iNGMAAHBlYQ8KEGTsNgeAumMPCgAAsA4BBQAAWIeveABc0Qdd8pUcYCf2oAAAAOuwBwUAUCfshUJ9IKAAQAOx7YJvgM34igcAAFiHgAIAAKzDVzywGrupAeDKxB4UAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrcJoxgBrhlG8ADYk9KAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYJaUDJz8/XNddco+joaKWlpWnbtm2hHA4AALBEyALKP//5T+Xk5GjGjBn69NNPdf311ysjI0PHjh0L1ZAAAIAlQhZQFixYoLFjx+qBBx5QSkqKFi1apJiYGC1dujRUQwIAAJaIDMWDlpaWqqCgQLm5uU5beHi40tPT5fV6q/QvKSlRSUmJc7+oqEiSVFxcXC/jqyg5Vy/bBQCgsaiPz9jKbRpjLts3JAHlxIkTKi8vV2Jiol97YmKi9u3bV6X/nDlzNHPmzCrtycnJ9TZGAACuZLFP1d+2T58+rdjY2Ev2CUlACVRubq5ycnKc+xUVFTp58qTatGmjsLCwoD5WcXGxkpOTdeTIEbnd7qBu2wbU1/g19Rqpr/Fr6jU29fqk+qvRGKPTp0+rXbt2l+0bkoDStm1bRUREqLCw0K+9sLBQSUlJVfq7XC65XC6/tri4uPocotxud5N94knU1xQ09Rqpr/Fr6jU29fqk+qnxcntOKoXkINmoqCj16dNHmzZtctoqKiq0adMmeTyeUAwJAABYJGRf8eTk5CgrK0t9+/ZVv3799NRTT+ns2bN64IEHQjUkAABgiZAFlJEjR+r48eOaPn26fD6fevfurQ0bNlQ5cLahuVwuzZgxo8pXSk0F9TV+Tb1G6mv8mnqNTb0+yY4aw0xNzvUBAABoQPwWDwAAsA4BBQAAWIeAAgAArENAAQAA1rniAspf//pXDRgwQDExMTW+2JsxRtOnT9fVV1+t5s2bKz09XV9++aVfn5MnT+ree++V2+1WXFycxowZozNnztRDBZcW6DgOHTqksLCwam+rVq1y+lW3fOXKlQ1RUhW1+VvfeuutVcb/0EMP+fU5fPiwMjMzFRMTo4SEBE2ePFllZWX1WUq1Aq3v5MmTmjBhgrp166bmzZurQ4cOevjhh53frKoUyjnMz8/XNddco+joaKWlpWnbtm2X7L9q1Sp1795d0dHRSk1N1bp16/yW1+Q12ZACqW/x4sX6+c9/rtatW6t169ZKT0+v0v/++++vMldDhgyp7zIuKpD6li9fXmXs0dHRfn1smz8psBqrez8JCwtTZmam08emOXz//ff1q1/9Su3atVNYWJhee+21y66zefNm3XjjjXK5XOrSpYuWL19epU+gr+uAmSvM9OnTzYIFC0xOTo6JjY2t0Tp5eXkmNjbWvPbaa+azzz4zv/71r02nTp3M999/7/QZMmSIuf76683HH39s/vWvf5kuXbqYu+++u56quLhAx1FWVma+/fZbv9vMmTNNy5YtzenTp51+ksyyZcv8+v2w/oZUm7/1wIEDzdixY/3GX1RU5CwvKyszPXv2NOnp6WbHjh1m3bp1pm3btiY3N7e+y6ki0Pp27dplhg8fbt544w1z4MABs2nTJtO1a1czYsQIv36hmsOVK1eaqKgos3TpUrN7924zduxYExcXZwoLC6vt/+GHH5qIiAgzd+5cs2fPHjNt2jTTrFkzs2vXLqdPTV6TDSXQ+u655x6Tn59vduzYYfbu3Wvuv/9+Exsba7755hunT1ZWlhkyZIjfXJ08ebKhSvITaH3Lli0zbrfbb+w+n8+vj03zZ0zgNX733Xd+9X3xxRcmIiLCLFu2zOlj0xyuW7fO/PnPfzavvvqqkWRWr159yf7//ve/TUxMjMnJyTF79uwxzz77rImIiDAbNmxw+gT6N6uNKy6gVFq2bFmNAkpFRYVJSkoy8+bNc9pOnTplXC6X+cc//mGMMWbPnj1Gktm+fbvTZ/369SYsLMz85z//CfrYLyZY4+jdu7f53e9+59dWkyd1Q6htjQMHDjSPPPLIRZevW7fOhIeH+72RPv/888btdpuSkpKgjL0mgjWHL7/8somKijIXLlxw2kI1h/369TPZ2dnO/fLyctOuXTszZ86cavv/9re/NZmZmX5taWlp5ve//70xpmavyYYUaH0/VlZWZlq1amVefPFFpy0rK8sMGzYs2EOtlUDru9x7q23zZ0zd53DhwoWmVatW5syZM06bTXP4QzV5H3jsscfMdddd59c2cuRIk5GR4dyv69+sJq64r3gCdfDgQfl8PqWnpzttsbGxSktLk9frlSR5vV7FxcWpb9++Tp/09HSFh4dr69atDTbWYIyjoKBAO3fu1JgxY6osy87OVtu2bdWvXz8tXbq0Rj+XHWx1qfGll15S27Zt1bNnT+Xm5urcuXN+201NTfW7UGBGRoaKi4u1e/fu4BdyEcF6LhUVFcntdisy0v9ajA09h6WlpSooKPB7/YSHhys9Pd15/fyY1+v16y/9by4q+9fkNdlQalPfj507d04XLlxQfHy8X/vmzZuVkJCgbt26ady4cfruu++COvaaqG19Z86cUceOHZWcnKxhw4b5vYZsmj8pOHO4ZMkSjRo1Si1atPBrt2EOa+Nyr8Fg/M1qolH8mnEo+Xw+SapyhdvExERnmc/nU0JCgt/yyMhIxcfHO30aQjDGsWTJEvXo0UMDBgzwa581a5Zuu+02xcTE6O2339Yf/vAHnTlzRg8//HDQxl8Tta3xnnvuUceOHdWuXTt9/vnnmjJlivbv369XX33V2W51c1y5rKEEYw5PnDih2bNn68EHH/RrD8UcnjhxQuXl5dX+bfft21ftOhebix++3irbLtanodSmvh+bMmWK2rVr5/dmP2TIEA0fPlydOnXSV199pT/96U8aOnSovF6vIiIiglrDpdSmvm7dumnp0qXq1auXioqKNH/+fA0YMEC7d+9W+/btrZo/qe5zuG3bNn3xxRdasmSJX7stc1gbF3sNFhcX6/vvv9d///vfOj/va6JJBJSpU6fqySefvGSfvXv3qnv37g00ouCqaX119f3332vFihV6/PHHqyz7YdsNN9ygs2fPat68eUH7cKvvGn/4YZ2amqqrr75agwYN0ldffaVrr7221tutqYaaw+LiYmVmZiolJUV/+ctf/JbV9xwicHl5eVq5cqU2b97sdyDpqFGjnH+npqaqV69euvbaa7V582YNGjQoFEOtMY/H4/ejrwMGDFCPHj30wgsvaPbs2SEcWf1YsmSJUlNT1a9fP7/2xjyHtmgSAeXRRx/V/ffff8k+nTt3rtW2k5KSJEmFhYW6+uqrnfbCwkL17t3b6XPs2DG/9crKynTy5Eln/bqoaX11Hccrr7yic+fO6b777rts37S0NM2ePVslJSVB+a2GhqqxUlpamiTpwIEDuvbaa5WUlFTlCPTCwkJJajRzePr0aQ0ZMkStWrXS6tWr1axZs0v2D/YcVqdt27aKiIhw/paVCgsLL1pPUlLSJfvX5DXZUGpTX6X58+crLy9P77zzjnr16nXJvp07d1bbtm114MCBBv1wq0t9lZo1a6YbbrhBBw4ckGTX/El1q/Hs2bNauXKlZs2addnHCdUc1sbFXoNut1vNmzdXREREnZ8XNRK0o1kamUAPkp0/f77TVlRUVO1Bsp988onT56233grZQbK1HcfAgQOrnPlxMU888YRp3bp1rcdaW8H6W3/wwQdGkvnss8+MMf//INkfHoH+wgsvGLfbbc6fPx+8Ai6jtvUVFRWZ/v37m4EDB5qzZ8/W6LEaag779etnxo8f79wvLy83P/nJTy55kOwdd9zh1+bxeKocJHup12RDCrQ+Y4x58sknjdvtNl6vt0aPceTIERMWFmZef/31Oo83ULWp74fKyspMt27dzKRJk4wx9s2fMbWvcdmyZcblcpkTJ05c9jFCOYc/pBoeJNuzZ0+/trvvvrvKQbJ1eV7UaKxB21Ij8fXXX5sdO3Y4p9Lu2LHD7Nixw++U2m7duplXX33VuZ+Xl2fi4uLM66+/bj7//HMzbNiwak8zvuGGG8zWrVvNBx98YLp27Rqy04wvNY5vvvnGdOvWzWzdutVvvS+//NKEhYWZ9evXV9nmG2+8YRYvXmx27dplvvzyS/Pcc8+ZmJgYM3369HqvpzqB1njgwAEza9Ys88knn5iDBw+a119/3XTu3NnccsstzjqVpxkPHjzY7Ny502zYsMFcddVVITvNOJD6ioqKTFpamklNTTUHDhzwO62xrKzMGBPaOVy5cqVxuVxm+fLlZs+ePebBBx80cXFxzhlTo0ePNlOnTnX6f/jhhyYyMtLMnz/f7N2718yYMaPa04wv95psKIHWl5eXZ6Kioswrr7ziN1eV70GnT582f/zjH43X6zUHDx4077zzjrnxxhtN165dGzQs17a+mTNnmrfeest89dVXpqCgwIwaNcpER0eb3bt3O31smj9jAq+x0s0332xGjhxZpd22OTx9+rTzWSfJLFiwwOzYscN8/fXXxhhjpk6dakaPHu30rzzNePLkyWbv3r0mPz+/2tOML/U3C4YrLqBkZWUZSVVu7733ntNH/3e9iEoVFRXm8ccfN4mJicblcplBgwaZ/fv3+233u+++M3fffbdp2bKlcbvd5oEHHvALPQ3lcuM4ePBglXqNMSY3N9ckJyeb8vLyKttcv3696d27t2nZsqVp0aKFuf76682iRYuq7dsQAq3x8OHD5pZbbjHx8fHG5XKZLl26mMmTJ/tdB8UYYw4dOmSGDh1qmjdvbtq2bWseffRRv9N0G0qg9b333nvVPqclmYMHDxpjQj+Hzz77rOnQoYOJiooy/fr1Mx9//LGzbODAgSYrK8uv/8svv2x++tOfmqioKHPdddeZN9980295TV6TDSmQ+jp27FjtXM2YMcMYY8y5c+fM4MGDzVVXXWWaNWtmOnbsaMaOHRvUN/5ABVLfxIkTnb6JiYnm9ttvN59++qnf9mybP2MCf47u27fPSDJvv/12lW3ZNocXe4+orCkrK8sMHDiwyjq9e/c2UVFRpnPnzn6fiZUu9TcLhjBjQnCuKAAAwCVwHRQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArPP/AATu3Xfiz/hBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(h.view(-1).tolist(), 50); # value of h passed to tanh so majority of it should not be close to 1,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eed32b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(hpreact.view(-1).tolist(), 50); # this is being passed to tanh, so higher value will result into 1 or -1\n",
    "# ti fix this we want it to close to uniform distribution with mean 0 and variance 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0333527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## loss log\n",
    "\n",
    "# ### original:\n",
    "# train 2.1245384216308594\n",
    "# val   2.168196439743042\n",
    "\n",
    "# ### fix softmax confidently wrong: (W2, B2)\n",
    "# train 2.07\n",
    "# val   2.13\n",
    "\n",
    "# ### fix tanh layer too saturated at init: (W1, B1)\n",
    "# train 2.0355966091156006\n",
    "# val   2.1026785373687744\n",
    "\n",
    "# ### use semi-principled \"kaiming init\" instead of hacky init:\n",
    "# train 2.0376641750335693\n",
    "# val   2.106989622116089\n",
    "\n",
    "# ### add batch norm layer\n",
    "# train 2.0668270587921143\n",
    "# val 2.104844808578491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes the first thing to pay attentions is initialization \n",
    "# Initial loss should have been 1/27, uniform distribution \n",
    "-torch.log(torch.tensor(1/27.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d12a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 dimensions example of the issue, so basically during initialization \n",
    "# logits is taking exterme value \n",
    "logits = torch.tensor([0.0, 0.0, 0.0, 0.0])\n",
    "probs = torch.softmax(logits, dim=0)\n",
    "loss = -probs[2].log()\n",
    "print(probs, loss)\n",
    "\n",
    "logits = torch.tensor([0.0, 0.0, 5.0, 0.0])\n",
    "probs = torch.softmax(logits, dim=0)\n",
    "loss = -probs[2].log()\n",
    "print(probs, loss) # low loss\n",
    "\n",
    "logits = torch.tensor([100.0, 0.0, 5.0, 0.0])\n",
    "probs = torch.softmax(logits, dim=0)\n",
    "loss = -probs[2].log()\n",
    "print(probs, loss) # high loss\n",
    "\n",
    "\n",
    "logits = torch.randn(4)\n",
    "probs = torch.softmax(logits, dim=0)\n",
    "loss = -probs[2].log()\n",
    "print(probs, loss) # high loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 # + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnstd = hpreact.std(0, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1  + b1\n",
    "  #hpreact = bngain * (hpreact - hpreact.mean(0, keepdim=True)) / hpreact.std(0, keepdim=True) + bnbias\n",
    "  #hpreact = bngain * (hpreact - bnmean) / bnstd + bnbias\n",
    "  hpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias\n",
    "  h = torch.tanh(hpreact)  \n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f6540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "      logits = h @ W2 + b2\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef5a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(1000, 10)\n",
    "w = torch.randn(10, 200) / 10**0.5\n",
    "y = x @ w \n",
    "print(x.mean(), x.std())\n",
    "print(w.mean(), w.std())\n",
    "print(y.mean(), y.std())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(121)\n",
    "plt.hist(x.view(-1).tolist(), 50, density=True);\n",
    "plt.subplot(122)\n",
    "plt.hist(w.view(-1).tolist(), 50, density=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa1966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous mean = 0 , std  =1 \n",
    "# after multiply mean = 0, std = 3 \n",
    "# so we want std to close std = 1, how do we set w such that after multiplication it stays gaussian \n",
    "# Try multiplying w by some numbers or divide to see how it goes\n",
    "# IT TURNS OUT BEST WAY TO GET ACTIVATION (Y) GAUSSIAN IS BY DIVIDING W BY SQUARE ROOT OF ITS FAN-IN\n",
    "print(y.mean(), y.std())\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(121)\n",
    "plt.hist(y.view(-1).tolist(), 50, density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes the first thing to pay attentions is initialization \n",
    "# Initial loss should have been 1/27, uniform distribution \n",
    "# First thing: Fix logits value to be uniform and small\n",
    "# second thing: Value of h which gets passed to tanh (-1, 1) at the edge the slope is 0\n",
    "#             This is dead neuron\n",
    "#.          basically tanh backward will be zero if tanh ~= 1 or -1 , flat region\n",
    "# if tanh =0 then gradient will just pass through \n",
    "# so if tanh=1 or -1 (dead neuron) or if tanh = 0 then gradient will be just pass by\n",
    "# so. we want some entropy so tanh should not be -1, 1 or 0\n",
    "# apart from flat region, a high learning rate can also caused the too much gradient and then it gets knocked out\n",
    "# During Initializaion it can also \n",
    "# so question is why do you use a function with flat tails ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY + PYTORCHIFYING -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02677a",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Let's train a deeper network\n",
    "# The classes we create here are the same API as nn.Module in PyTorch\n",
    "\n",
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out), generator=g) / fan_in**0.5\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      xmean = x.mean(0, keepdim=True) # batch mean\n",
    "      xvar = x.var(0, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 100 # the number of neurons in the hidden layer of the MLP\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "layers = [\n",
    "  Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "  Linear(           n_hidden, vocab_size, bias=False), BatchNorm1d(vocab_size),\n",
    "]\n",
    "# layers = [\n",
    "#   Linear(n_embd * block_size, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, n_hidden), Tanh(),\n",
    "#   Linear(           n_hidden, vocab_size),\n",
    "# ]\n",
    "\n",
    "with torch.no_grad():\n",
    "  # last layer: make less confident\n",
    "  layers[-1].gamma *= 0.1\n",
    "  #layers[-1].weight *= 0.1\n",
    "  # all other layers: apply gain\n",
    "  for layer in layers[:-1]:\n",
    "    if isinstance(layer, Linear):\n",
    "      layer.weight *= 1.0 #5/3\n",
    "\n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076dad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[Xb] # embed the characters into vectors\n",
    "  x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "  for layer in layers:\n",
    "    x = layer(x)\n",
    "  loss = F.cross_entropy(x, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for layer in layers:\n",
    "    layer.out.retain_grad() # AFTER_DEBUG: would take out retain_graph\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr =  1.0 #0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "  with torch.no_grad():\n",
    "    ud.append([((lr*p.grad).std() / p.data.std()).log10().item() for p in parameters])\n",
    "\n",
    "  if i >= 1000:\n",
    "    break # AFTER_DEBUG: would take out obviously to run full optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423fde3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i, layer in enumerate(layers[:-1]): # note: exclude the output layer\n",
    "  if isinstance(layer, Tanh):\n",
    "    t = layer.out\n",
    "    print('layer %d (%10s): mean %+.2f, std %.2f, saturated: %.2f%%' % (i, layer.__class__.__name__, t.mean(), t.std(), (t.abs() > 0.97).float().mean()*100))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'layer {i} ({layer.__class__.__name__}')\n",
    "plt.legend(legends);\n",
    "plt.title('activation distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i, layer in enumerate(layers[:-1]): # note: exclude the output layer\n",
    "  if isinstance(layer, Tanh):\n",
    "    t = layer.out.grad\n",
    "    print('layer %d (%10s): mean %+f, std %e' % (i, layer.__class__.__name__, t.mean(), t.std()))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'layer {i} ({layer.__class__.__name__}')\n",
    "plt.legend(legends);\n",
    "plt.title('gradient distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 4)) # width and height of the plot\n",
    "legends = []\n",
    "for i,p in enumerate(parameters):\n",
    "  t = p.grad\n",
    "  if p.ndim == 2:\n",
    "    print('weight %10s | mean %+f | std %e | grad:data ratio %e' % (tuple(p.shape), t.mean(), t.std(), t.std() / p.std()))\n",
    "    hy, hx = torch.histogram(t, density=True)\n",
    "    plt.plot(hx[:-1].detach(), hy.detach())\n",
    "    legends.append(f'{i} {tuple(p.shape)}')\n",
    "plt.legend(legends)\n",
    "plt.title('weights gradient distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e809dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "for i,p in enumerate(parameters):\n",
    "  if p.ndim == 2:\n",
    "    plt.plot([ud[j][i] for j in range(len(ud))])\n",
    "    legends.append('param %d' % i)\n",
    "plt.plot([0, len(ud)], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "plt.legend(legends);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6cf030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be68d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1df2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
