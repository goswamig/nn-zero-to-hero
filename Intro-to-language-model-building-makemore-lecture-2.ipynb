{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d16dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067f3492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45dde345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ab6674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(w) for w in words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7727a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e071f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing biagram\n",
    "b = {}\n",
    "for w in words:\n",
    "    chs = ['<S>'] + list(w) + ['<E>']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        biagram = (ch1, ch2)\n",
    "        b[biagram] = b.get(biagram, 0) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "710454f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '<E>'), 6763),\n",
       " (('a', '<E>'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('<S>', 'a'), 4410),\n",
       " (('e', '<E>'), 3983),\n",
       " (('a', 'r'), 3264),\n",
       " (('e', 'l'), 3248),\n",
       " (('r', 'i'), 3033),\n",
       " (('n', 'a'), 2977),\n",
       " (('<S>', 'k'), 2963),\n",
       " (('l', 'e'), 2921),\n",
       " (('e', 'n'), 2675),\n",
       " (('l', 'a'), 2623),\n",
       " (('m', 'a'), 2590),\n",
       " (('<S>', 'm'), 2538),\n",
       " (('a', 'l'), 2528),\n",
       " (('i', '<E>'), 2489),\n",
       " (('l', 'i'), 2480),\n",
       " (('i', 'a'), 2445),\n",
       " (('<S>', 'j'), 2422),\n",
       " (('o', 'n'), 2411),\n",
       " (('h', '<E>'), 2409),\n",
       " (('r', 'a'), 2356),\n",
       " (('a', 'h'), 2332),\n",
       " (('h', 'a'), 2244),\n",
       " (('y', 'a'), 2143),\n",
       " (('i', 'n'), 2126),\n",
       " (('<S>', 's'), 2055),\n",
       " (('a', 'y'), 2050),\n",
       " (('y', '<E>'), 2007),\n",
       " (('e', 'r'), 1958),\n",
       " (('n', 'n'), 1906),\n",
       " (('y', 'n'), 1826),\n",
       " (('k', 'a'), 1731),\n",
       " (('n', 'i'), 1725),\n",
       " (('r', 'e'), 1697),\n",
       " (('<S>', 'd'), 1690),\n",
       " (('i', 'e'), 1653),\n",
       " (('a', 'i'), 1650),\n",
       " (('<S>', 'r'), 1639),\n",
       " (('a', 'm'), 1634),\n",
       " (('l', 'y'), 1588),\n",
       " (('<S>', 'l'), 1572),\n",
       " (('<S>', 'c'), 1542),\n",
       " (('<S>', 'e'), 1531),\n",
       " (('j', 'a'), 1473),\n",
       " (('r', '<E>'), 1377),\n",
       " (('n', 'e'), 1359),\n",
       " (('l', 'l'), 1345),\n",
       " (('i', 'l'), 1345),\n",
       " (('i', 's'), 1316),\n",
       " (('l', '<E>'), 1314),\n",
       " (('<S>', 't'), 1308),\n",
       " (('<S>', 'b'), 1306),\n",
       " (('d', 'a'), 1303),\n",
       " (('s', 'h'), 1285),\n",
       " (('d', 'e'), 1283),\n",
       " (('e', 'e'), 1271),\n",
       " (('m', 'i'), 1256),\n",
       " (('s', 'a'), 1201),\n",
       " (('s', '<E>'), 1169),\n",
       " (('<S>', 'n'), 1146),\n",
       " (('a', 's'), 1118),\n",
       " (('y', 'l'), 1104),\n",
       " (('e', 'y'), 1070),\n",
       " (('o', 'r'), 1059),\n",
       " (('a', 'd'), 1042),\n",
       " (('t', 'a'), 1027),\n",
       " (('<S>', 'z'), 929),\n",
       " (('v', 'i'), 911),\n",
       " (('k', 'e'), 895),\n",
       " (('s', 'e'), 884),\n",
       " (('<S>', 'h'), 874),\n",
       " (('r', 'o'), 869),\n",
       " (('e', 's'), 861),\n",
       " (('z', 'a'), 860),\n",
       " (('o', '<E>'), 855),\n",
       " (('i', 'r'), 849),\n",
       " (('b', 'r'), 842),\n",
       " (('a', 'v'), 834),\n",
       " (('m', 'e'), 818),\n",
       " (('e', 'i'), 818),\n",
       " (('c', 'a'), 815),\n",
       " (('i', 'y'), 779),\n",
       " (('r', 'y'), 773),\n",
       " (('e', 'm'), 769),\n",
       " (('s', 't'), 765),\n",
       " (('h', 'i'), 729),\n",
       " (('t', 'e'), 716),\n",
       " (('n', 'd'), 704),\n",
       " (('l', 'o'), 692),\n",
       " (('a', 'e'), 692),\n",
       " (('a', 't'), 687),\n",
       " (('s', 'i'), 684),\n",
       " (('e', 'a'), 679),\n",
       " (('d', 'i'), 674),\n",
       " (('h', 'e'), 674),\n",
       " (('<S>', 'g'), 669),\n",
       " (('t', 'o'), 667),\n",
       " (('c', 'h'), 664),\n",
       " (('b', 'e'), 655),\n",
       " (('t', 'h'), 647),\n",
       " (('v', 'a'), 642),\n",
       " (('o', 'l'), 619),\n",
       " (('<S>', 'i'), 591),\n",
       " (('i', 'o'), 588),\n",
       " (('e', 't'), 580),\n",
       " (('v', 'e'), 568),\n",
       " (('a', 'k'), 568),\n",
       " (('a', 'a'), 556),\n",
       " (('c', 'e'), 551),\n",
       " (('a', 'b'), 541),\n",
       " (('i', 't'), 541),\n",
       " (('<S>', 'y'), 535),\n",
       " (('t', 'i'), 532),\n",
       " (('s', 'o'), 531),\n",
       " (('m', '<E>'), 516),\n",
       " (('d', '<E>'), 516),\n",
       " (('<S>', 'p'), 515),\n",
       " (('i', 'c'), 509),\n",
       " (('k', 'i'), 509),\n",
       " (('o', 's'), 504),\n",
       " (('n', 'o'), 496),\n",
       " (('t', '<E>'), 483),\n",
       " (('j', 'o'), 479),\n",
       " (('u', 's'), 474),\n",
       " (('a', 'c'), 470),\n",
       " (('n', 'y'), 465),\n",
       " (('e', 'v'), 463),\n",
       " (('s', 's'), 461),\n",
       " (('m', 'o'), 452),\n",
       " (('i', 'k'), 445),\n",
       " (('n', 't'), 443),\n",
       " (('i', 'd'), 440),\n",
       " (('j', 'e'), 440),\n",
       " (('a', 'z'), 435),\n",
       " (('i', 'g'), 428),\n",
       " (('i', 'm'), 427),\n",
       " (('r', 'r'), 425),\n",
       " (('d', 'r'), 424),\n",
       " (('<S>', 'f'), 417),\n",
       " (('u', 'r'), 414),\n",
       " (('r', 'l'), 413),\n",
       " (('y', 's'), 401),\n",
       " (('<S>', 'o'), 394),\n",
       " (('e', 'd'), 384),\n",
       " (('a', 'u'), 381),\n",
       " (('c', 'o'), 380),\n",
       " (('k', 'y'), 379),\n",
       " (('d', 'o'), 378),\n",
       " (('<S>', 'v'), 376),\n",
       " (('t', 't'), 374),\n",
       " (('z', 'e'), 373),\n",
       " (('z', 'i'), 364),\n",
       " (('k', '<E>'), 363),\n",
       " (('g', 'h'), 360),\n",
       " (('t', 'r'), 352),\n",
       " (('k', 'o'), 344),\n",
       " (('t', 'y'), 341),\n",
       " (('g', 'e'), 334),\n",
       " (('g', 'a'), 330),\n",
       " (('l', 'u'), 324),\n",
       " (('b', 'a'), 321),\n",
       " (('d', 'y'), 317),\n",
       " (('c', 'k'), 316),\n",
       " (('<S>', 'w'), 307),\n",
       " (('k', 'h'), 307),\n",
       " (('u', 'l'), 301),\n",
       " (('y', 'e'), 301),\n",
       " (('y', 'r'), 291),\n",
       " (('m', 'y'), 287),\n",
       " (('h', 'o'), 287),\n",
       " (('w', 'a'), 280),\n",
       " (('s', 'l'), 279),\n",
       " (('n', 's'), 278),\n",
       " (('i', 'z'), 277),\n",
       " (('u', 'n'), 275),\n",
       " (('o', 'u'), 275),\n",
       " (('n', 'g'), 273),\n",
       " (('y', 'd'), 272),\n",
       " (('c', 'i'), 271),\n",
       " (('y', 'o'), 271),\n",
       " (('i', 'v'), 269),\n",
       " (('e', 'o'), 269),\n",
       " (('o', 'm'), 261),\n",
       " (('r', 'u'), 252),\n",
       " (('f', 'a'), 242),\n",
       " (('b', 'i'), 217),\n",
       " (('s', 'y'), 215),\n",
       " (('n', 'c'), 213),\n",
       " (('h', 'y'), 213),\n",
       " (('p', 'a'), 209),\n",
       " (('r', 't'), 208),\n",
       " (('q', 'u'), 206),\n",
       " (('p', 'h'), 204),\n",
       " (('h', 'r'), 204),\n",
       " (('j', 'u'), 202),\n",
       " (('g', 'r'), 201),\n",
       " (('p', 'e'), 197),\n",
       " (('n', 'l'), 195),\n",
       " (('y', 'i'), 192),\n",
       " (('g', 'i'), 190),\n",
       " (('o', 'd'), 190),\n",
       " (('r', 's'), 190),\n",
       " (('r', 'd'), 187),\n",
       " (('h', 'l'), 185),\n",
       " (('s', 'u'), 185),\n",
       " (('a', 'x'), 182),\n",
       " (('e', 'z'), 181),\n",
       " (('e', 'k'), 178),\n",
       " (('o', 'v'), 176),\n",
       " (('a', 'j'), 175),\n",
       " (('o', 'h'), 171),\n",
       " (('u', 'e'), 169),\n",
       " (('m', 'm'), 168),\n",
       " (('a', 'g'), 168),\n",
       " (('h', 'u'), 166),\n",
       " (('x', '<E>'), 164),\n",
       " (('u', 'a'), 163),\n",
       " (('r', 'm'), 162),\n",
       " (('a', 'w'), 161),\n",
       " (('f', 'i'), 160),\n",
       " (('z', '<E>'), 160),\n",
       " (('u', '<E>'), 155),\n",
       " (('u', 'm'), 154),\n",
       " (('e', 'c'), 153),\n",
       " (('v', 'o'), 153),\n",
       " (('e', 'h'), 152),\n",
       " (('p', 'r'), 151),\n",
       " (('d', 'd'), 149),\n",
       " (('o', 'a'), 149),\n",
       " (('w', 'e'), 149),\n",
       " (('w', 'i'), 148),\n",
       " (('y', 'm'), 148),\n",
       " (('z', 'y'), 147),\n",
       " (('n', 'z'), 145),\n",
       " (('y', 'u'), 141),\n",
       " (('r', 'n'), 140),\n",
       " (('o', 'b'), 140),\n",
       " (('k', 'l'), 139),\n",
       " (('m', 'u'), 139),\n",
       " (('l', 'd'), 138),\n",
       " (('h', 'n'), 138),\n",
       " (('u', 'd'), 136),\n",
       " (('<S>', 'x'), 134),\n",
       " (('t', 'l'), 134),\n",
       " (('a', 'f'), 134),\n",
       " (('o', 'e'), 132),\n",
       " (('e', 'x'), 132),\n",
       " (('e', 'g'), 125),\n",
       " (('f', 'e'), 123),\n",
       " (('z', 'l'), 123),\n",
       " (('u', 'i'), 121),\n",
       " (('v', 'y'), 121),\n",
       " (('e', 'b'), 121),\n",
       " (('r', 'h'), 121),\n",
       " (('j', 'i'), 119),\n",
       " (('o', 't'), 118),\n",
       " (('d', 'h'), 118),\n",
       " (('h', 'm'), 117),\n",
       " (('c', 'l'), 116),\n",
       " (('o', 'o'), 115),\n",
       " (('y', 'c'), 115),\n",
       " (('o', 'w'), 114),\n",
       " (('o', 'c'), 114),\n",
       " (('f', 'r'), 114),\n",
       " (('b', '<E>'), 114),\n",
       " (('m', 'b'), 112),\n",
       " (('z', 'o'), 110),\n",
       " (('i', 'b'), 110),\n",
       " (('i', 'u'), 109),\n",
       " (('k', 'r'), 109),\n",
       " (('g', '<E>'), 108),\n",
       " (('y', 'v'), 106),\n",
       " (('t', 'z'), 105),\n",
       " (('b', 'o'), 105),\n",
       " (('c', 'y'), 104),\n",
       " (('y', 't'), 104),\n",
       " (('u', 'b'), 103),\n",
       " (('u', 'c'), 103),\n",
       " (('x', 'a'), 103),\n",
       " (('b', 'l'), 103),\n",
       " (('o', 'y'), 103),\n",
       " (('x', 'i'), 102),\n",
       " (('i', 'f'), 101),\n",
       " (('r', 'c'), 99),\n",
       " (('c', '<E>'), 97),\n",
       " (('m', 'r'), 97),\n",
       " (('n', 'u'), 96),\n",
       " (('o', 'p'), 95),\n",
       " (('i', 'h'), 95),\n",
       " (('k', 's'), 95),\n",
       " (('l', 's'), 94),\n",
       " (('u', 'k'), 93),\n",
       " (('<S>', 'q'), 92),\n",
       " (('d', 'u'), 92),\n",
       " (('s', 'm'), 90),\n",
       " (('r', 'k'), 90),\n",
       " (('i', 'x'), 89),\n",
       " (('v', '<E>'), 88),\n",
       " (('y', 'k'), 86),\n",
       " (('u', 'w'), 86),\n",
       " (('g', 'u'), 85),\n",
       " (('b', 'y'), 83),\n",
       " (('e', 'p'), 83),\n",
       " (('g', 'o'), 83),\n",
       " (('s', 'k'), 82),\n",
       " (('u', 't'), 82),\n",
       " (('a', 'p'), 82),\n",
       " (('e', 'f'), 82),\n",
       " (('i', 'i'), 82),\n",
       " (('r', 'v'), 80),\n",
       " (('f', '<E>'), 80),\n",
       " (('t', 'u'), 78),\n",
       " (('y', 'z'), 78),\n",
       " (('<S>', 'u'), 78),\n",
       " (('l', 't'), 77),\n",
       " (('r', 'g'), 76),\n",
       " (('c', 'r'), 76),\n",
       " (('i', 'j'), 76),\n",
       " (('w', 'y'), 73),\n",
       " (('z', 'u'), 73),\n",
       " (('l', 'v'), 72),\n",
       " (('h', 't'), 71),\n",
       " (('j', '<E>'), 71),\n",
       " (('x', 't'), 70),\n",
       " (('o', 'i'), 69),\n",
       " (('e', 'u'), 69),\n",
       " (('o', 'k'), 68),\n",
       " (('b', 'd'), 65),\n",
       " (('a', 'o'), 63),\n",
       " (('p', 'i'), 61),\n",
       " (('s', 'c'), 60),\n",
       " (('d', 'l'), 60),\n",
       " (('l', 'm'), 60),\n",
       " (('a', 'q'), 60),\n",
       " (('f', 'o'), 60),\n",
       " (('p', 'o'), 59),\n",
       " (('n', 'k'), 58),\n",
       " (('w', 'n'), 58),\n",
       " (('u', 'h'), 58),\n",
       " (('e', 'j'), 55),\n",
       " (('n', 'v'), 55),\n",
       " (('s', 'r'), 55),\n",
       " (('o', 'z'), 54),\n",
       " (('i', 'p'), 53),\n",
       " (('l', 'b'), 52),\n",
       " (('i', 'q'), 52),\n",
       " (('w', '<E>'), 51),\n",
       " (('m', 'c'), 51),\n",
       " (('s', 'p'), 51),\n",
       " (('e', 'w'), 50),\n",
       " (('k', 'u'), 50),\n",
       " (('v', 'r'), 48),\n",
       " (('u', 'g'), 47),\n",
       " (('o', 'x'), 45),\n",
       " (('u', 'z'), 45),\n",
       " (('z', 'z'), 45),\n",
       " (('j', 'h'), 45),\n",
       " (('b', 'u'), 45),\n",
       " (('o', 'g'), 44),\n",
       " (('n', 'r'), 44),\n",
       " (('f', 'f'), 44),\n",
       " (('n', 'j'), 44),\n",
       " (('z', 'h'), 43),\n",
       " (('c', 'c'), 42),\n",
       " (('r', 'b'), 41),\n",
       " (('x', 'o'), 41),\n",
       " (('b', 'h'), 41),\n",
       " (('p', 'p'), 39),\n",
       " (('x', 'l'), 39),\n",
       " (('h', 'v'), 39),\n",
       " (('b', 'b'), 38),\n",
       " (('m', 'p'), 38),\n",
       " (('x', 'x'), 38),\n",
       " (('u', 'v'), 37),\n",
       " (('x', 'e'), 36),\n",
       " (('w', 'o'), 36),\n",
       " (('c', 't'), 35),\n",
       " (('z', 'm'), 35),\n",
       " (('t', 's'), 35),\n",
       " (('m', 's'), 35),\n",
       " (('c', 'u'), 35),\n",
       " (('o', 'f'), 34),\n",
       " (('u', 'x'), 34),\n",
       " (('k', 'w'), 34),\n",
       " (('p', '<E>'), 33),\n",
       " (('g', 'l'), 32),\n",
       " (('z', 'r'), 32),\n",
       " (('d', 'n'), 31),\n",
       " (('g', 't'), 31),\n",
       " (('g', 'y'), 31),\n",
       " (('h', 's'), 31),\n",
       " (('x', 's'), 31),\n",
       " (('g', 's'), 30),\n",
       " (('x', 'y'), 30),\n",
       " (('y', 'g'), 30),\n",
       " (('d', 'm'), 30),\n",
       " (('d', 's'), 29),\n",
       " (('h', 'k'), 29),\n",
       " (('y', 'x'), 28),\n",
       " (('q', '<E>'), 28),\n",
       " (('g', 'n'), 27),\n",
       " (('y', 'b'), 27),\n",
       " (('g', 'w'), 26),\n",
       " (('n', 'h'), 26),\n",
       " (('k', 'n'), 26),\n",
       " (('g', 'g'), 25),\n",
       " (('d', 'g'), 25),\n",
       " (('l', 'c'), 25),\n",
       " (('r', 'j'), 25),\n",
       " (('w', 'u'), 25),\n",
       " (('l', 'k'), 24),\n",
       " (('m', 'd'), 24),\n",
       " (('s', 'w'), 24),\n",
       " (('s', 'n'), 24),\n",
       " (('h', 'd'), 24),\n",
       " (('w', 'h'), 23),\n",
       " (('y', 'j'), 23),\n",
       " (('y', 'y'), 23),\n",
       " (('r', 'z'), 23),\n",
       " (('d', 'w'), 23),\n",
       " (('w', 'r'), 22),\n",
       " (('t', 'n'), 22),\n",
       " (('l', 'f'), 22),\n",
       " (('y', 'h'), 22),\n",
       " (('r', 'w'), 21),\n",
       " (('s', 'b'), 21),\n",
       " (('m', 'n'), 20),\n",
       " (('f', 'l'), 20),\n",
       " (('w', 's'), 20),\n",
       " (('k', 'k'), 20),\n",
       " (('h', 'z'), 20),\n",
       " (('g', 'd'), 19),\n",
       " (('l', 'h'), 19),\n",
       " (('n', 'm'), 19),\n",
       " (('x', 'z'), 19),\n",
       " (('u', 'f'), 19),\n",
       " (('f', 't'), 18),\n",
       " (('l', 'r'), 18),\n",
       " (('p', 't'), 17),\n",
       " (('t', 'c'), 17),\n",
       " (('k', 't'), 17),\n",
       " (('d', 'v'), 17),\n",
       " (('u', 'p'), 16),\n",
       " (('p', 'l'), 16),\n",
       " (('l', 'w'), 16),\n",
       " (('p', 's'), 16),\n",
       " (('o', 'j'), 16),\n",
       " (('r', 'q'), 16),\n",
       " (('y', 'p'), 15),\n",
       " (('l', 'p'), 15),\n",
       " (('t', 'v'), 15),\n",
       " (('r', 'p'), 14),\n",
       " (('l', 'n'), 14),\n",
       " (('e', 'q'), 14),\n",
       " (('f', 'y'), 14),\n",
       " (('s', 'v'), 14),\n",
       " (('u', 'j'), 14),\n",
       " (('v', 'l'), 14),\n",
       " (('q', 'a'), 13),\n",
       " (('u', 'y'), 13),\n",
       " (('q', 'i'), 13),\n",
       " (('w', 'l'), 13),\n",
       " (('p', 'y'), 12),\n",
       " (('y', 'f'), 12),\n",
       " (('c', 'q'), 11),\n",
       " (('j', 'r'), 11),\n",
       " (('n', 'w'), 11),\n",
       " (('n', 'f'), 11),\n",
       " (('t', 'w'), 11),\n",
       " (('m', 'z'), 11),\n",
       " (('u', 'o'), 10),\n",
       " (('f', 'u'), 10),\n",
       " (('l', 'z'), 10),\n",
       " (('h', 'w'), 10),\n",
       " (('u', 'q'), 10),\n",
       " (('j', 'y'), 10),\n",
       " (('s', 'z'), 10),\n",
       " (('s', 'd'), 9),\n",
       " (('j', 'l'), 9),\n",
       " (('d', 'j'), 9),\n",
       " (('k', 'm'), 9),\n",
       " (('r', 'f'), 9),\n",
       " (('h', 'j'), 9),\n",
       " (('v', 'n'), 8),\n",
       " (('n', 'b'), 8),\n",
       " (('i', 'w'), 8),\n",
       " (('h', 'b'), 8),\n",
       " (('b', 's'), 8),\n",
       " (('w', 't'), 8),\n",
       " (('w', 'd'), 8),\n",
       " (('v', 'v'), 7),\n",
       " (('v', 'u'), 7),\n",
       " (('j', 's'), 7),\n",
       " (('m', 'j'), 7),\n",
       " (('f', 's'), 6),\n",
       " (('l', 'g'), 6),\n",
       " (('l', 'j'), 6),\n",
       " (('j', 'w'), 6),\n",
       " (('n', 'x'), 6),\n",
       " (('y', 'q'), 6),\n",
       " (('w', 'k'), 6),\n",
       " (('g', 'm'), 6),\n",
       " (('x', 'u'), 5),\n",
       " (('m', 'h'), 5),\n",
       " (('m', 'l'), 5),\n",
       " (('j', 'm'), 5),\n",
       " (('c', 's'), 5),\n",
       " (('j', 'v'), 5),\n",
       " (('n', 'p'), 5),\n",
       " (('d', 'f'), 5),\n",
       " (('x', 'd'), 5),\n",
       " (('z', 'b'), 4),\n",
       " (('f', 'n'), 4),\n",
       " (('x', 'c'), 4),\n",
       " (('m', 't'), 4),\n",
       " (('t', 'm'), 4),\n",
       " (('z', 'n'), 4),\n",
       " (('z', 't'), 4),\n",
       " (('p', 'u'), 4),\n",
       " (('c', 'z'), 4),\n",
       " (('b', 'n'), 4),\n",
       " (('z', 's'), 4),\n",
       " (('f', 'w'), 4),\n",
       " (('d', 't'), 4),\n",
       " (('j', 'd'), 4),\n",
       " (('j', 'c'), 4),\n",
       " (('y', 'w'), 4),\n",
       " (('v', 'k'), 3),\n",
       " (('x', 'w'), 3),\n",
       " (('t', 'j'), 3),\n",
       " (('c', 'j'), 3),\n",
       " (('q', 'w'), 3),\n",
       " (('g', 'b'), 3),\n",
       " (('o', 'q'), 3),\n",
       " (('r', 'x'), 3),\n",
       " (('d', 'c'), 3),\n",
       " (('g', 'j'), 3),\n",
       " (('x', 'f'), 3),\n",
       " (('z', 'w'), 3),\n",
       " (('d', 'k'), 3),\n",
       " (('u', 'u'), 3),\n",
       " (('m', 'v'), 3),\n",
       " (('c', 'x'), 3),\n",
       " (('l', 'q'), 3),\n",
       " (('p', 'b'), 2),\n",
       " (('t', 'g'), 2),\n",
       " (('q', 's'), 2),\n",
       " (('t', 'x'), 2),\n",
       " (('f', 'k'), 2),\n",
       " (('b', 't'), 2),\n",
       " (('j', 'n'), 2),\n",
       " (('k', 'c'), 2),\n",
       " (('z', 'k'), 2),\n",
       " (('s', 'j'), 2),\n",
       " (('s', 'f'), 2),\n",
       " (('z', 'j'), 2),\n",
       " (('n', 'q'), 2),\n",
       " (('f', 'z'), 2),\n",
       " (('h', 'g'), 2),\n",
       " (('w', 'w'), 2),\n",
       " (('k', 'j'), 2),\n",
       " (('j', 'k'), 2),\n",
       " (('w', 'm'), 2),\n",
       " (('z', 'c'), 2),\n",
       " (('z', 'v'), 2),\n",
       " (('w', 'f'), 2),\n",
       " (('q', 'm'), 2),\n",
       " (('k', 'z'), 2),\n",
       " (('j', 'j'), 2),\n",
       " (('z', 'p'), 2),\n",
       " (('j', 't'), 2),\n",
       " (('k', 'b'), 2),\n",
       " (('m', 'w'), 2),\n",
       " (('h', 'f'), 2),\n",
       " (('c', 'g'), 2),\n",
       " (('t', 'f'), 2),\n",
       " (('h', 'c'), 2),\n",
       " (('q', 'o'), 2),\n",
       " (('k', 'd'), 2),\n",
       " (('k', 'v'), 2),\n",
       " (('s', 'g'), 2),\n",
       " (('z', 'd'), 2),\n",
       " (('q', 'r'), 1),\n",
       " (('d', 'z'), 1),\n",
       " (('p', 'j'), 1),\n",
       " (('q', 'l'), 1),\n",
       " (('p', 'f'), 1),\n",
       " (('q', 'e'), 1),\n",
       " (('b', 'c'), 1),\n",
       " (('c', 'd'), 1),\n",
       " (('m', 'f'), 1),\n",
       " (('p', 'n'), 1),\n",
       " (('w', 'b'), 1),\n",
       " (('p', 'c'), 1),\n",
       " (('h', 'p'), 1),\n",
       " (('f', 'h'), 1),\n",
       " (('b', 'j'), 1),\n",
       " (('f', 'g'), 1),\n",
       " (('z', 'g'), 1),\n",
       " (('c', 'p'), 1),\n",
       " (('p', 'k'), 1),\n",
       " (('p', 'm'), 1),\n",
       " (('x', 'n'), 1),\n",
       " (('s', 'q'), 1),\n",
       " (('k', 'f'), 1),\n",
       " (('m', 'k'), 1),\n",
       " (('x', 'h'), 1),\n",
       " (('g', 'f'), 1),\n",
       " (('v', 'b'), 1),\n",
       " (('j', 'p'), 1),\n",
       " (('g', 'z'), 1),\n",
       " (('v', 'd'), 1),\n",
       " (('d', 'b'), 1),\n",
       " (('v', 'h'), 1),\n",
       " (('h', 'h'), 1),\n",
       " (('g', 'v'), 1),\n",
       " (('d', 'q'), 1),\n",
       " (('x', 'b'), 1),\n",
       " (('w', 'z'), 1),\n",
       " (('h', 'q'), 1),\n",
       " (('j', 'b'), 1),\n",
       " (('x', 'm'), 1),\n",
       " (('w', 'g'), 1),\n",
       " (('t', 'b'), 1),\n",
       " (('z', 'x'), 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(b.items(), key = lambda kv: -kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5fa0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets build 2D array of 26 + 2('<S>' and '<E>') \n",
    "# where row and columns are these characters and \n",
    "# value in cell are counts of (row, col) pair\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a96422ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "N =torch.zeros((28, 28), dtype=torch.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f736c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "# char to int\n",
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "stoi['<S>'] = 26\n",
    "stoi['<E>'] = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74883a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = ['<S>'] + list(w) + ['<E>']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1][ix2] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc8a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse of int to char \n",
    "itos = {i: s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a7e36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1209160d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.imshow(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b646be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d240f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you notice above one has something like character then <S> \n",
    "# or <E> then character which will always such case will not occur\n",
    "# instead of <S> and <E> we will use only one special char '.'\n",
    "N = torch.zeros((27, 27), dtype=torch.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac58c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "# char to int\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}  # {'.':0, 'a':1, 'b':2, ....}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}   # {0:'.', 1:'a', 2:'b', ....}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e7838b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1][ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "119e7e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1217fc8e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e52e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a2363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "        1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "         134,  535,  929], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0, :] # first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7893edf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets convert them into probability\n",
    "p = N[0].float()\n",
    "p /= p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "309e0f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77565424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e48e95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d0d237c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = N.float() # P is same size as N\n",
    "# lets do model smoothing (to avoid prob of getting q after m to be 0), just make it 1\n",
    "P = (N + 1).float()\n",
    "P.sum(1, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e59d34f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1221e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1192e-05, 1.3759e-01, 4.0767e-02, 4.8129e-02, 5.2745e-02, 4.7785e-02,\n",
       "         1.3038e-02, 2.0898e-02, 2.7293e-02, 1.8465e-02, 7.5577e-02, 9.2452e-02,\n",
       "         4.9064e-02, 7.9195e-02, 3.5777e-02, 1.2321e-02, 1.6095e-02, 2.9008e-03,\n",
       "         5.1154e-02, 6.4130e-02, 4.0830e-02, 2.4641e-03, 1.1759e-02, 9.6070e-03,\n",
       "         4.2109e-03, 1.6719e-02, 2.9008e-02],\n",
       "        [1.9583e-01, 1.6425e-02, 1.5983e-02, 1.3889e-02, 3.0756e-02, 2.0435e-02,\n",
       "         3.9809e-03, 4.9835e-03, 6.8796e-02, 4.8685e-02, 5.1899e-03, 1.6779e-02,\n",
       "         7.4575e-02, 4.8213e-02, 1.6039e-01, 1.8872e-03, 2.4475e-03, 1.7988e-03,\n",
       "         9.6279e-02, 3.2997e-02, 2.0288e-02, 1.1264e-02, 2.4623e-02, 4.7771e-03,\n",
       "         5.3963e-03, 6.0480e-02, 1.2857e-02],\n",
       "        [4.3039e-02, 1.2051e-01, 1.4596e-02, 7.4850e-04, 2.4701e-02, 2.4551e-01,\n",
       "         3.7425e-04, 3.7425e-04, 1.5719e-02, 8.1587e-02, 7.4850e-04, 3.7425e-04,\n",
       "         3.8922e-02, 3.7425e-04, 1.8713e-03, 3.9671e-02, 3.7425e-04, 3.7425e-04,\n",
       "         3.1549e-01, 3.3683e-03, 1.1228e-03, 1.7216e-02, 3.7425e-04, 3.7425e-04,\n",
       "         3.7425e-04, 3.1437e-02, 3.7425e-04],\n",
       "        [2.7536e-02, 2.2928e-01, 2.8098e-04, 1.2082e-02, 5.6196e-04, 1.5510e-01,\n",
       "         2.8098e-04, 8.4293e-04, 1.8685e-01, 7.6426e-02, 1.1239e-03, 8.9070e-02,\n",
       "         3.2874e-02, 2.8098e-04, 2.8098e-04, 1.0705e-01, 5.6196e-04, 3.3717e-03,\n",
       "         2.1635e-02, 1.6859e-03, 1.0115e-02, 1.0115e-02, 2.8098e-04, 2.8098e-04,\n",
       "         1.1239e-03, 2.9503e-02, 1.4049e-03],\n",
       "        [9.3609e-02, 2.3610e-01, 3.6212e-04, 7.2424e-04, 2.7159e-02, 2.3248e-01,\n",
       "         1.0864e-03, 4.7076e-03, 2.1546e-02, 1.2222e-01, 1.8106e-03, 7.2424e-04,\n",
       "         1.1045e-02, 5.6129e-03, 5.7940e-03, 6.8622e-02, 1.8106e-04, 3.6212e-04,\n",
       "         7.6951e-02, 5.4318e-03, 9.0531e-04, 1.6839e-02, 3.2591e-03, 4.3455e-03,\n",
       "         1.8106e-04, 5.7577e-02, 3.6212e-04],\n",
       "        [1.9482e-01, 3.3252e-02, 5.9658e-03, 7.5306e-03, 1.8826e-02, 6.2200e-02,\n",
       "         4.0587e-03, 6.1614e-03, 7.4817e-03, 4.0049e-02, 2.7384e-03, 8.7531e-03,\n",
       "         1.5888e-01, 3.7653e-02, 1.3086e-01, 1.3203e-02, 4.1076e-03, 7.3350e-04,\n",
       "         9.5795e-02, 4.2152e-02, 2.8411e-02, 3.4230e-03, 2.2689e-02, 2.4939e-03,\n",
       "         6.5037e-03, 5.2372e-02, 8.8998e-03],\n",
       "        [8.6910e-02, 2.6073e-01, 1.0730e-03, 1.0730e-03, 1.0730e-03, 1.3305e-01,\n",
       "         4.8283e-02, 2.1459e-03, 2.1459e-03, 1.7275e-01, 1.0730e-03, 3.2189e-03,\n",
       "         2.2532e-02, 1.0730e-03, 5.3648e-03, 6.5451e-02, 1.0730e-03, 1.0730e-03,\n",
       "         1.2339e-01, 7.5107e-03, 2.0386e-02, 1.1803e-02, 1.0730e-03, 5.3648e-03,\n",
       "         1.0730e-03, 1.6094e-02, 3.2189e-03],\n",
       "        [5.5783e-02, 1.6940e-01, 2.0471e-03, 5.1177e-04, 1.0235e-02, 1.7144e-01,\n",
       "         1.0235e-03, 1.3306e-02, 1.8475e-01, 9.7748e-02, 2.0471e-03, 5.1177e-04,\n",
       "         1.6888e-02, 3.5824e-03, 1.4330e-02, 4.2989e-02, 5.1177e-04, 5.1177e-04,\n",
       "         1.0338e-01, 1.5865e-02, 1.6377e-02, 4.4012e-02, 1.0235e-03, 1.3818e-02,\n",
       "         5.1177e-04, 1.6377e-02, 1.0235e-03],\n",
       "        [3.1532e-01, 2.9373e-01, 1.1775e-03, 3.9252e-04, 3.2710e-03, 8.8316e-02,\n",
       "         3.9252e-04, 3.9252e-04, 2.6168e-04, 9.5512e-02, 1.3084e-03, 3.9252e-03,\n",
       "         2.4336e-02, 1.5439e-02, 1.8187e-02, 3.7682e-02, 2.6168e-04, 2.6168e-04,\n",
       "         2.6822e-02, 4.1868e-03, 9.4204e-03, 2.1850e-02, 5.2335e-03, 1.4392e-03,\n",
       "         1.3084e-04, 2.7999e-02, 2.7476e-03],\n",
       "        [1.4046e-01, 1.3797e-01, 6.2613e-03, 2.8768e-02, 2.4876e-02, 9.3299e-02,\n",
       "         5.7536e-03, 2.4199e-02, 5.4152e-03, 4.6819e-03, 4.3434e-03, 2.5158e-02,\n",
       "         7.5925e-02, 2.4143e-02, 1.1998e-01, 3.3224e-02, 3.0460e-03, 2.9896e-03,\n",
       "         4.7947e-02, 7.4289e-02, 3.0573e-02, 6.2049e-03, 1.5230e-02, 5.0767e-04,\n",
       "         5.0767e-03, 4.3998e-02, 1.5681e-02],\n",
       "        [2.4599e-02, 5.0359e-01, 6.8329e-04, 1.7082e-03, 1.7082e-03, 1.5067e-01,\n",
       "         3.4165e-04, 3.4165e-04, 1.5716e-02, 4.0998e-02, 1.0249e-03, 1.0249e-03,\n",
       "         3.4165e-03, 2.0499e-03, 1.0249e-03, 1.6399e-01, 6.8329e-04, 3.4165e-04,\n",
       "         4.0998e-03, 2.7332e-03, 1.0249e-03, 6.9354e-02, 2.0499e-03, 2.3915e-03,\n",
       "         3.4165e-04, 3.7581e-03, 3.4165e-04],\n",
       "        [7.1837e-02, 3.4182e-01, 5.9207e-04, 5.9207e-04, 5.9207e-04, 1.7683e-01,\n",
       "         3.9471e-04, 1.9736e-04, 6.0785e-02, 1.0065e-01, 5.9207e-04, 4.1445e-03,\n",
       "         2.7630e-02, 1.9736e-03, 5.3286e-03, 6.8088e-02, 1.9736e-04, 1.9736e-04,\n",
       "         2.1709e-02, 1.8946e-02, 3.5524e-03, 1.0065e-02, 5.9207e-04, 6.9074e-03,\n",
       "         1.9736e-04, 7.4995e-02, 5.9207e-04],\n",
       "        [9.4029e-02, 1.8763e-01, 3.7898e-03, 1.8591e-03, 9.9392e-03, 2.0894e-01,\n",
       "         1.6446e-03, 5.0054e-04, 1.4301e-03, 1.7740e-01, 5.0054e-04, 1.7876e-03,\n",
       "         9.6246e-02, 4.3618e-03, 1.0726e-03, 4.9553e-02, 1.1441e-03, 2.8602e-04,\n",
       "         1.3586e-03, 6.7930e-03, 5.5774e-03, 2.3239e-02, 5.2199e-03, 1.2156e-03,\n",
       "         7.1505e-05, 1.1362e-01, 7.8656e-04],\n",
       "        [7.7523e-02, 3.8851e-01, 1.6944e-02, 7.7973e-03, 3.7487e-03, 1.2281e-01,\n",
       "         2.9990e-04, 1.4995e-04, 8.9969e-04, 1.8848e-01, 1.1996e-03, 2.9990e-04,\n",
       "         8.9969e-04, 2.5341e-02, 3.1489e-03, 6.7926e-02, 5.8480e-03, 1.4995e-04,\n",
       "         1.4695e-02, 5.3981e-03, 7.4974e-04, 2.0993e-02, 5.9979e-04, 4.4984e-04,\n",
       "         1.4995e-04, 4.3185e-02, 1.7994e-03],\n",
       "        [3.6853e-01, 1.6225e-01, 4.9036e-04, 1.1660e-02, 3.8411e-02, 7.4098e-02,\n",
       "         6.5381e-04, 1.4929e-02, 1.4711e-03, 9.4039e-02, 2.4518e-03, 3.2146e-03,\n",
       "         1.0679e-02, 1.0897e-03, 1.0390e-01, 2.7079e-02, 3.2690e-04, 1.6345e-04,\n",
       "         2.4518e-03, 1.5201e-02, 2.4191e-02, 5.2850e-03, 3.0511e-03, 6.5381e-04,\n",
       "         3.8139e-04, 2.5390e-02, 7.9547e-03],\n",
       "        [1.0752e-01, 1.8842e-02, 1.7711e-02, 1.4445e-02, 2.3992e-02, 1.6706e-02,\n",
       "         4.3964e-03, 5.6526e-03, 2.1605e-02, 8.7929e-03, 2.1354e-03, 8.6673e-03,\n",
       "         7.7880e-02, 3.2910e-02, 3.0298e-01, 1.4571e-02, 1.2059e-02, 5.0245e-04,\n",
       "         1.3315e-01, 6.3434e-02, 1.4948e-02, 3.4669e-02, 2.2233e-02, 1.4445e-02,\n",
       "         5.7782e-03, 1.3064e-02, 6.9087e-03],\n",
       "        [3.2289e-02, 1.9943e-01, 2.8490e-03, 1.8993e-03, 9.4967e-04, 1.8803e-01,\n",
       "         1.8993e-03, 9.4967e-04, 1.9468e-01, 5.8879e-02, 1.8993e-03, 1.8993e-03,\n",
       "         1.6144e-02, 1.8993e-03, 1.8993e-03, 5.6980e-02, 3.7987e-02, 9.4967e-04,\n",
       "         1.4435e-01, 1.6144e-02, 1.7094e-02, 4.7483e-03, 9.4967e-04, 9.4967e-04,\n",
       "         9.4967e-04, 1.2346e-02, 9.4967e-04],\n",
       "        [9.6990e-02, 4.6823e-02, 3.3445e-03, 3.3445e-03, 3.3445e-03, 6.6890e-03,\n",
       "         3.3445e-03, 3.3445e-03, 3.3445e-03, 4.6823e-02, 3.3445e-03, 3.3445e-03,\n",
       "         6.6890e-03, 1.0033e-02, 3.3445e-03, 1.0033e-02, 3.3445e-03, 3.3445e-03,\n",
       "         6.6890e-03, 1.0033e-02, 3.3445e-03, 6.9231e-01, 3.3445e-03, 1.3378e-02,\n",
       "         3.3445e-03, 3.3445e-03, 3.3445e-03],\n",
       "        [1.0827e-01, 1.8520e-01, 3.3001e-03, 7.8573e-03, 1.4772e-02, 1.3342e-01,\n",
       "         7.8573e-04, 6.0501e-03, 9.5859e-03, 2.3839e-01, 2.0429e-03, 7.1502e-03,\n",
       "         3.2529e-02, 1.2807e-02, 1.1079e-02, 6.8359e-02, 1.1786e-03, 1.3357e-03,\n",
       "         3.3472e-02, 1.5007e-02, 1.6422e-02, 1.9879e-02, 6.3644e-03, 1.7286e-03,\n",
       "         3.1429e-04, 6.0816e-02, 1.8858e-03],\n",
       "        [1.4386e-01, 1.4779e-01, 2.7050e-03, 7.5003e-03, 1.2296e-03, 1.0882e-01,\n",
       "         3.6887e-04, 3.6887e-04, 1.5812e-01, 8.4225e-02, 3.6887e-04, 1.0205e-02,\n",
       "         3.4428e-02, 1.1189e-02, 3.0739e-03, 6.5413e-02, 6.3937e-03, 2.4591e-04,\n",
       "         6.8855e-03, 5.6806e-02, 9.4184e-02, 2.2870e-02, 1.8443e-03, 3.0739e-03,\n",
       "         1.2296e-04, 2.6558e-02, 1.3525e-03],\n",
       "        [8.6475e-02, 1.8367e-01, 3.5733e-04, 3.2160e-03, 1.7867e-04, 1.2810e-01,\n",
       "         5.3600e-04, 5.3600e-04, 1.1578e-01, 9.5230e-02, 7.1467e-04, 1.7867e-04,\n",
       "         2.4120e-02, 8.9334e-04, 4.1093e-03, 1.1935e-01, 1.7867e-04, 1.7867e-04,\n",
       "         6.3070e-02, 6.4320e-03, 6.7000e-02, 1.4115e-02, 2.8587e-03, 2.1440e-03,\n",
       "         5.3600e-04, 6.1104e-02, 1.8939e-02],\n",
       "        [4.9336e-02, 5.1866e-02, 3.2891e-02, 3.2891e-02, 4.3327e-02, 5.3763e-02,\n",
       "         6.3251e-03, 1.5180e-02, 1.8659e-02, 3.8583e-02, 4.7438e-03, 2.9728e-02,\n",
       "         9.5509e-02, 4.9020e-02, 8.7287e-02, 3.4788e-03, 5.3763e-03, 3.4788e-03,\n",
       "         1.3125e-01, 1.5022e-01, 2.6249e-02, 1.2650e-03, 1.2018e-02, 2.7514e-02,\n",
       "         1.1069e-02, 4.4276e-03, 1.4548e-02],\n",
       "        [3.4231e-02, 2.4731e-01, 7.6923e-04, 3.8462e-04, 7.6923e-04, 2.1885e-01,\n",
       "         3.8462e-04, 3.8462e-04, 7.6923e-04, 3.5077e-01, 3.8462e-04, 1.5385e-03,\n",
       "         5.7692e-03, 3.8462e-04, 3.4615e-03, 5.9231e-02, 3.8462e-04, 3.8462e-04,\n",
       "         1.8846e-02, 3.8462e-04, 3.8462e-04, 3.0769e-03, 3.0769e-03, 3.8462e-04,\n",
       "         3.8462e-04, 4.6923e-02, 3.8462e-04],\n",
       "        [5.4393e-02, 2.9393e-01, 2.0921e-03, 1.0460e-03, 9.4142e-03, 1.5690e-01,\n",
       "         3.1381e-03, 2.0921e-03, 2.5105e-02, 1.5586e-01, 1.0460e-03, 7.3222e-03,\n",
       "         1.4644e-02, 3.1381e-03, 6.1715e-02, 3.8703e-02, 1.0460e-03, 1.0460e-03,\n",
       "         2.4059e-02, 2.1967e-02, 9.4142e-03, 2.7197e-02, 1.0460e-03, 3.1381e-03,\n",
       "         1.0460e-03, 7.7406e-02, 2.0921e-03],\n",
       "        [2.2790e-01, 1.4365e-01, 2.7624e-03, 6.9061e-03, 8.2873e-03, 5.1105e-02,\n",
       "         5.5249e-03, 1.3812e-03, 2.7624e-03, 1.4227e-01, 1.3812e-03, 1.3812e-03,\n",
       "         5.5249e-02, 2.7624e-03, 2.7624e-03, 5.8011e-02, 1.3812e-03, 1.3812e-03,\n",
       "         1.3812e-03, 4.4199e-02, 9.8066e-02, 8.2873e-03, 1.3812e-03, 5.5249e-03,\n",
       "         5.3867e-02, 4.2818e-02, 2.7624e-02],\n",
       "        [2.0484e-01, 2.1871e-01, 2.8563e-03, 1.1833e-02, 2.7849e-02, 3.0807e-02,\n",
       "         1.3261e-03, 3.1623e-03, 2.3462e-03, 1.9688e-02, 2.4482e-03, 8.8748e-03,\n",
       "         1.1272e-01, 1.5199e-02, 1.8637e-01, 2.7747e-02, 1.6322e-03, 7.1407e-04,\n",
       "         2.9787e-02, 4.1008e-02, 1.0711e-02, 1.4485e-02, 1.0915e-02, 5.1005e-04,\n",
       "         2.9583e-03, 2.4482e-03, 8.0588e-03],\n",
       "        [6.6392e-02, 3.5505e-01, 2.0619e-03, 1.2371e-03, 1.2371e-03, 1.5423e-01,\n",
       "         4.1237e-04, 8.2474e-04, 1.8144e-02, 1.5052e-01, 1.2371e-03, 1.2371e-03,\n",
       "         5.1134e-02, 1.4845e-02, 2.0619e-03, 4.5773e-02, 1.2371e-03, 4.1237e-04,\n",
       "         1.3608e-02, 2.0619e-03, 2.0619e-03, 3.0515e-02, 1.2371e-03, 1.6495e-03,\n",
       "         8.2474e-04, 6.1031e-02, 1.8969e-02]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the https://pytorch.org/docs/stable/notes/broadcasting.html\n",
    "P /= P.sum(1, keepdim=True)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49a1e7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[0].sum() # make sure each row sums to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dae4c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor.\n",
      "axx.\n",
      "minaymoryles.\n",
      "kondlaisah.\n",
      "anchshizarie.\n"
     ]
    }
   ],
   "source": [
    "# generate new names \n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0 # first row \n",
    "    while True:\n",
    "        #p = P[ix]\n",
    "        # p = N[ix].float()\n",
    "        # p /= p.sum() \n",
    "        # below line just generates uniform distributed which is untrained model, \n",
    "        # uncomment below to see how a un-trained model behaves\n",
    "        # p = torch.ones(27) /27.0\n",
    "        ix = torch.multinomial(P[ix], num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0: # we went back to first row and it will return same since generator is same\n",
    "            break \n",
    "    print(''.join(out))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e58574a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6064, 0.3033, 0.0903])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can sample from distribution\n",
    "# torch.multinomial \n",
    "# Generator makes everything deterministic\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "p = torch.rand(3, generator=g)\n",
    "p = p / p.sum()\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f878d9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2, 0, 0, 2, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(p, num_samples=10, replacement=True, generator=g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b22e0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
    "# equivalent to maximizing the log likelihood (because log is monotonic)\n",
    "# equivalent to minimizing the negative log likelihood\n",
    "# equivalent to minimizing the average negative log likelihood\n",
    "\n",
    "# log(a*b*c) = log(a) + log(b) + log(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79f3bc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_liklihood=tensor(-29.6349)\n",
      "nll=tensor(29.6349)\n",
      "nll/n=tensor(3.7044)\n"
     ]
    }
   ],
   "source": [
    "# Lets try to evaluate the quality of this biagram model\n",
    "# How do we evaluate this model in single number\n",
    "# we use Maximum liklihood estimation(MLE) of log(probability)\n",
    "# MLE uses product of prob, so log(prob) will be sum\n",
    "log_liklihood = 0.0\n",
    "n = 0\n",
    "#for w in words:\n",
    "for w in [\"gautamq\"]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1][ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_liklihood += logprob\n",
    "        n += 1\n",
    "        #print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
    "print(f'{log_liklihood=}')  \n",
    "# Above number is either 0 (when all prob is 1, log(1)=0) or very high \n",
    "# negative number, but loss function should be minimum so we take negative \n",
    "# log liklihood(ll)\n",
    "nll = -log_liklihood\n",
    "print(f'{nll=}')  \n",
    "print(f'{nll/n=}')  \n",
    "# so the job is to minimize negative of log liklihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5540f57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037037037037037035"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probablitiy of selecting any character out of 27 is\n",
    "# 1/27.0 so anything above 1/27.o meaning model learned \n",
    "# something \n",
    "1/27.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80ba123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do same thing using neural network.\n",
    "# we have loss functional nll (negative likelihood)\n",
    "# input will be one character and output will be one character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86a59e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e\n",
      "e m\n",
      "m m\n",
      "m a\n",
      "a .\n"
     ]
    }
   ],
   "source": [
    "# create training set of all bigrams (x, y)\n",
    "# lets use gradient based optimization \n",
    "xs, ys = [], []\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        print(ch1, ch2)\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fe82ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c82d7788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ef9cc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1de2be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can't feed directly integer but rather we encode it\n",
    "# one-hot encoding.\n",
    "import torch.nn.functional as F\n",
    "#when we pass the input we want them to be float,\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "yenc = F.one_hot(ys, num_classes=27).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ceb9780f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89abb685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x120ab0220>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83c2e575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a9cec44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c143c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4506)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randn(27, 27)\n",
    "(xenc @ w) # shape is (5, 27)\n",
    "(xenc @ w)[3, 13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86c7b7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4506)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xenc[3]*w[13]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1437f70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0151, 0.0441, 0.0317, 0.0129, 0.0085, 0.0410, 0.0324, 0.0880, 0.0384,\n",
       "         0.1172, 0.0187, 0.0045, 0.0162, 0.0210, 0.0805, 0.0016, 0.0291, 0.0081,\n",
       "         0.1357, 0.0275, 0.0151, 0.0196, 0.0884, 0.0073, 0.0167, 0.0386, 0.0421],\n",
       "        [0.0214, 0.0029, 0.0215, 0.0491, 0.0123, 0.0048, 0.0303, 0.0757, 0.2492,\n",
       "         0.0380, 0.0253, 0.0262, 0.0451, 0.0320, 0.0037, 0.0367, 0.0105, 0.0422,\n",
       "         0.0049, 0.0213, 0.0356, 0.0084, 0.0253, 0.0833, 0.0479, 0.0341, 0.0124],\n",
       "        [0.0476, 0.0290, 0.0348, 0.0288, 0.0289, 0.0608, 0.2057, 0.0600, 0.0546,\n",
       "         0.0093, 0.0238, 0.0813, 0.0338, 0.0110, 0.0064, 0.0091, 0.0169, 0.0560,\n",
       "         0.0287, 0.0257, 0.0035, 0.0099, 0.0231, 0.0488, 0.0030, 0.0480, 0.0114],\n",
       "        [0.0476, 0.0290, 0.0348, 0.0288, 0.0289, 0.0608, 0.2057, 0.0600, 0.0546,\n",
       "         0.0093, 0.0238, 0.0813, 0.0338, 0.0110, 0.0064, 0.0091, 0.0169, 0.0560,\n",
       "         0.0287, 0.0257, 0.0035, 0.0099, 0.0231, 0.0488, 0.0030, 0.0480, 0.0114],\n",
       "        [0.0070, 0.0423, 0.0500, 0.0111, 0.1735, 0.0096, 0.0323, 0.0080, 0.0374,\n",
       "         0.0782, 0.0205, 0.0114, 0.0649, 0.0054, 0.0463, 0.0117, 0.0107, 0.0320,\n",
       "         0.0133, 0.0096, 0.0125, 0.0143, 0.1040, 0.0647, 0.0768, 0.0280, 0.0247]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will treat them as log so we will exponent \n",
    "logits = xenc @ w\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dbc1743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd25024d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f449ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4d907fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs # input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ec9b46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys # desired output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78aaa701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons weight, each neuron recieves 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3fa2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass \n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "logits = xenc @ W\n",
    "# last two lines are softmax used mostly in classifications\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abb292de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a4a24d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "bigram example 1: .e (indexes 0,5)\n",
      "input to the neural net: 0\n",
      "output probabilities from the neural net: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
      "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
      "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459])\n",
      "label (actual next character): 5\n",
      "probability assigned by the net to the the correct character: 0.012286253273487091\n",
      "log likelihood: -4.3992743492126465\n",
      "negative log likelihood: 4.3992743492126465\n",
      "--------\n",
      "bigram example 2: em (indexes 5,13)\n",
      "input to the neural net: 5\n",
      "output probabilities from the neural net: tensor([0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
      "        0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
      "        0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.018050702288746834\n",
      "log likelihood: -4.014570713043213\n",
      "negative log likelihood: 4.014570713043213\n",
      "--------\n",
      "bigram example 3: mm (indexes 13,13)\n",
      "input to the neural net: 13\n",
      "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
      "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
      "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the the correct character: 0.026691533625125885\n",
      "log likelihood: -3.623408794403076\n",
      "negative log likelihood: 3.623408794403076\n",
      "--------\n",
      "bigram example 4: ma (indexes 13,1)\n",
      "input to the neural net: 13\n",
      "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
      "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
      "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
      "label (actual next character): 1\n",
      "probability assigned by the net to the the correct character: 0.07367684692144394\n",
      "log likelihood: -2.6080667972564697\n",
      "negative log likelihood: 2.6080667972564697\n",
      "--------\n",
      "bigram example 5: a. (indexes 1,0)\n",
      "input to the neural net: 1\n",
      "output probabilities from the neural net: tensor([0.0150, 0.0086, 0.0396, 0.0100, 0.0606, 0.0308, 0.1084, 0.0131, 0.0125,\n",
      "        0.0048, 0.1024, 0.0086, 0.0988, 0.0112, 0.0232, 0.0207, 0.0408, 0.0078,\n",
      "        0.0899, 0.0531, 0.0463, 0.0309, 0.0051, 0.0329, 0.0654, 0.0503, 0.0091])\n",
      "label (actual next character): 0\n",
      "probability assigned by the net to the the correct character: 0.0149775305762887\n",
      "log likelihood: -4.201204299926758\n",
      "negative log likelihood: 4.201204299926758\n",
      "=========\n",
      "average negative log likelihood, i.e. loss = 3.7693049907684326\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "  # i-th bigram:\n",
    "  x = xs[i].item() # input character index\n",
    "  y = ys[i].item() # label character index\n",
    "  print('--------')\n",
    "  print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "  print('input to the neural net:', x)\n",
    "  print('output probabilities from the neural net:', probs[i])\n",
    "  print('label (actual next character):', y)\n",
    "  p = probs[i, y]\n",
    "  print('probability assigned by the net to the the correct character:', p.item())\n",
    "  logp = torch.log(p)\n",
    "  print('log likelihood:', logp.item())\n",
    "  nll = -logp\n",
    "  print('negative log likelihood:', nll.item())\n",
    "  nlls[i] = nll\n",
    "\n",
    "print('=========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bfd3e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- !!! OPTIMIZATION !!! yay --------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c561489e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59283392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8233a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2f69193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "# probs[0, 5], probs[1, 13], probs[2, 13], probs[3, 1], probs[4, 0]\n",
    "# negative average of log likelihood\n",
    "loss = -probs[torch.arange(5), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec36f589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7693, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a34d3dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # setting gradient zero\n",
    "loss.backward()\n",
    "\n",
    "# update the parameters \n",
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e91b5141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac8db462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b67d80bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- !!! OPTIMIZATION !!! yay, but this time actually --------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e9b44b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d5b2367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "iteration 1, loss 3.7686190605163574\n",
      "torch.Size([])\n",
      "iteration 2, loss 3.172484874725342\n",
      "torch.Size([])\n",
      "iteration 3, loss 2.9527597427368164\n",
      "torch.Size([])\n",
      "iteration 4, loss 2.8341522216796875\n",
      "torch.Size([])\n",
      "iteration 5, loss 2.7628936767578125\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "iterations = 5\n",
    "for i in range(iterations): \n",
    "    # forward pass \n",
    "    xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() +  + 0.01*(W**2).mean() # second term is regularization\n",
    "    print(loss.shape)\n",
    "    print(f'iteration {i+1}, loss {loss.item()}')\n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update the params \n",
    "    W.data += -90*W.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b74a8e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrla.\n",
      "wxcjonaynnnxrer.\n",
      "krelodfrah.\n",
      "anansiqzarie.\n",
      "pccn.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    #p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b88efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- !!! OPTIMIZATION !!! Playing with it with two layers --------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "96900614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W1 = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "W2 = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "499dcdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "iteration 1, loss 2.5248165130615234\n",
      "torch.Size([])\n",
      "iteration 2, loss 2.5174520015716553\n",
      "torch.Size([])\n",
      "iteration 3, loss 2.5206289291381836\n",
      "torch.Size([])\n",
      "iteration 4, loss 2.5149261951446533\n",
      "torch.Size([])\n",
      "iteration 5, loss 2.5185022354125977\n",
      "torch.Size([])\n",
      "iteration 6, loss 2.5158615112304688\n",
      "torch.Size([])\n",
      "iteration 7, loss 2.5203921794891357\n",
      "torch.Size([])\n",
      "iteration 8, loss 2.5245559215545654\n",
      "torch.Size([])\n",
      "iteration 9, loss 2.5258474349975586\n",
      "torch.Size([])\n",
      "iteration 10, loss 2.5343918800354004\n",
      "torch.Size([])\n",
      "iteration 11, loss 2.524855852127075\n",
      "torch.Size([])\n",
      "iteration 12, loss 2.5263218879699707\n",
      "torch.Size([])\n",
      "iteration 13, loss 2.5188770294189453\n",
      "torch.Size([])\n",
      "iteration 14, loss 2.5180766582489014\n",
      "torch.Size([])\n",
      "iteration 15, loss 2.514256477355957\n",
      "torch.Size([])\n",
      "iteration 16, loss 2.5131795406341553\n",
      "torch.Size([])\n",
      "iteration 17, loss 2.5106515884399414\n",
      "torch.Size([])\n",
      "iteration 18, loss 2.509347677230835\n",
      "torch.Size([])\n",
      "iteration 19, loss 2.5072426795959473\n",
      "torch.Size([])\n",
      "iteration 20, loss 2.5059235095977783\n",
      "torch.Size([])\n",
      "iteration 21, loss 2.504009246826172\n",
      "torch.Size([])\n",
      "iteration 22, loss 2.502880096435547\n",
      "torch.Size([])\n",
      "iteration 23, loss 2.501080274581909\n",
      "torch.Size([])\n",
      "iteration 24, loss 2.5002338886260986\n",
      "torch.Size([])\n",
      "iteration 25, loss 2.498504161834717\n",
      "torch.Size([])\n",
      "iteration 26, loss 2.4979569911956787\n",
      "torch.Size([])\n",
      "iteration 27, loss 2.4962666034698486\n",
      "torch.Size([])\n",
      "iteration 28, loss 2.4960052967071533\n",
      "torch.Size([])\n",
      "iteration 29, loss 2.4943349361419678\n",
      "torch.Size([])\n",
      "iteration 30, loss 2.494340658187866\n",
      "torch.Size([])\n",
      "iteration 31, loss 2.492680072784424\n",
      "torch.Size([])\n",
      "iteration 32, loss 2.4929416179656982\n",
      "torch.Size([])\n",
      "iteration 33, loss 2.4912922382354736\n",
      "torch.Size([])\n",
      "iteration 34, loss 2.491811752319336\n",
      "torch.Size([])\n",
      "iteration 35, loss 2.4901909828186035\n",
      "torch.Size([])\n",
      "iteration 36, loss 2.4909915924072266\n",
      "torch.Size([])\n",
      "iteration 37, loss 2.4894399642944336\n",
      "torch.Size([])\n",
      "iteration 38, loss 2.4905803203582764\n",
      "torch.Size([])\n",
      "iteration 39, loss 2.48917293548584\n",
      "torch.Size([])\n",
      "iteration 40, loss 2.490766763687134\n",
      "torch.Size([])\n",
      "iteration 41, loss 2.4896116256713867\n",
      "torch.Size([])\n",
      "iteration 42, loss 2.491852045059204\n",
      "torch.Size([])\n",
      "iteration 43, loss 2.491032838821411\n",
      "torch.Size([])\n",
      "iteration 44, loss 2.494168281555176\n",
      "torch.Size([])\n",
      "iteration 45, loss 2.4935410022735596\n",
      "torch.Size([])\n",
      "iteration 46, loss 2.497657537460327\n",
      "torch.Size([])\n",
      "iteration 47, loss 2.4965808391571045\n",
      "torch.Size([])\n",
      "iteration 48, loss 2.501182794570923\n",
      "torch.Size([])\n",
      "iteration 49, loss 2.498836040496826\n",
      "torch.Size([])\n",
      "iteration 50, loss 2.502873420715332\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "iterations = 50\n",
    "for i in range(iterations): \n",
    "    # forward pass \n",
    "    xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "    logits1 = xenc @ W1 # predict log-counts\n",
    "    logits = logits1 @ W2 \n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()   + 0.01*(W1**2).mean() + 0.0001*(W2**2).mean() # second term is regularization\n",
    "    print(loss.shape)\n",
    "    print(f'iteration {i+1}, loss {loss.item()}')\n",
    "    # backward pass\n",
    "    W1.grad = None\n",
    "    W2.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update the params \n",
    "    W1.data += -5*W1.grad\n",
    "    W2.data += -10*W2.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "90cf0589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrla.\n",
      "wxcjonaynnnxrer.\n",
      "krelodfrah.\n",
      "anansiqzarie.\n",
      "pccn.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    #p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4732b961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdcb11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
